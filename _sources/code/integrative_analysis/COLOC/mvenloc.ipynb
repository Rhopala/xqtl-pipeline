{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worldwide-territory",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Multivariate SuSiE and FastENLOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-underground",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-behavior",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook aims to demonstrate a workflow of generating posterior inclusion probabilities (PIPs) from GWAS summary statistics using SuSiE linear regression and construsting SNP signal clusters from global eQTL analysis data obtained from multivariate SuSiE models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-telling",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-democracy",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1) GWAS Summary Statistics with the following columns:\n",
    "- chr: chromosome number\n",
    "- bp: base pair position\n",
    "- a1: effect allele\n",
    "- a2: other allele\n",
    "- beta: effect size\n",
    "- se: standard error of beta\n",
    "- z: z score\n",
    "\n",
    "2) eQTL data from multivariate SuSiE model with the following columns:\n",
    "- chr: chromosome number\n",
    "- bp: base pair position\n",
    "- a1: effect allele\n",
    "- a2: other allele\n",
    "- pip: posterior inclusion probability\n",
    "\n",
    "3) LD correlation matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-olympus",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-algebra",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Intermediate files:\n",
    "\n",
    "1) GWAS PIP file with the following columns\n",
    "- var_id\n",
    "- ld_block \n",
    "- snp_pip\n",
    "- block_pip\n",
    "\n",
    "2) eQTL annotation file with the following columns\n",
    "- chr\n",
    "- bp\n",
    "- var_id\n",
    "- a1\n",
    "- a2\n",
    "- annotations, in the form: gene:cs_num@tissue=snp_pip[cs_pip:cs_total_snps] \n",
    "\n",
    "\n",
    "Final Outputs:\n",
    "\n",
    "1) Enrichment analysis result prefix.enloc.enrich.rst: estimated enrichment parameters and standard errors.\n",
    "\n",
    "2) Signal-level colocalization result prefix.enloc.sig.out: the main output from the colocalization analysis with the following format\n",
    "- column 1: signal cluster name (from eQTL analysis)\n",
    "- column 2: number of member SNPs\n",
    "- column 3: cluster PIP of eQTLs\n",
    "- column 4: cluster PIP of GWAS hits (without eQTL prior)\n",
    "- column 5: cluster PIP of GWAS hits (with eQTL prior)\n",
    "- column 6: regional colocalization probability (RCP)\n",
    "\n",
    "3) SNP-level colocalization result prefix.enloc.snp.out: SNP-level colocalization output with the following form at\n",
    "- column 1: signal cluster name\n",
    "- column 2: SNP name\n",
    "- column 3: SNP-level PIP of eQTLs\n",
    "- column 4: SNP-level PIP of GWAS (without eQTL prior)\n",
    "- column 5: SNP-level PIP of GWAS (with eQTL prior)\n",
    "- column 6: SNP-level colocalization probability\n",
    "\n",
    "4) Sorted list of colocalization signals with\n",
    "`sort -grk6 prefix.enloc.sig.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-american",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-activation",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Allele Flip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-assist",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Takes into consideration 3 situations: \n",
    "\n",
    "1) \"Major\" and \"minor\" alleles flipped\n",
    "\n",
    "2) Different strand but same variant\n",
    "\n",
    "3) Remove variants with A/T and C/G alleles due to ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bf929-7920-4e31-9e11-761dc40176e7",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b02dcf-a772-4ecd-9bef-cafd42f738fe",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb merge \\\n",
    "    --cwd output \\\n",
    "    --eqtl-sumstats .. \\\n",
    "    --gwas-sumstats .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7315b1-9f02-4702-90b4-8439b8bc7a12",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb eqtl \\\n",
    "    --cwd output \\\n",
    "    --sumstats-file .. \\\n",
    "    --ld-region .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf2629-8b3d-4ab7-a554-33d527a50ba1",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb gwas \\\n",
    "    --cwd output \\\n",
    "    --sumstats-file .. \\\n",
    "    --ld-region .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70201feb-f8b5-42d6-8e09-dd22f90633de",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb enloc \\\n",
    "    --cwd output \\\n",
    "    --eqtl-pip .. \\\n",
    "    --gwas-pip .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ee75d-d788-4a62-b7c9-21b104703a9d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53a875-bd53-457e-bd02-11e57b2ba677",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.enrich.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320add0-0c64-424c-bc2d-53b0ab5240ba",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.sig.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88448b-ad24-4b32-9142-99341e1f3819",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.snp.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93003ab1-8da1-4606-b3b4-c1f1bc62ad5a",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b33928-f85a-4e7d-b7e9-ad5b4ec890cf",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-hydrogen",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e745ad-d055-4201-bd87-b74583f6bc86",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path\n",
    "parameter: container = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-enemy",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### Step 0: data formatting\n",
    "\n",
    "#### Extract common SNPS between the GWAS summary statistics and eQTL data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc2c7f6-00c0-48bd-9ad1-ad89b4c45d91",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[merger]\n",
    "# eQTL summary statistics as a list of RData\n",
    "# FIXME: to replace later\n",
    "parameter: eqtl_sumstats = path \n",
    "# GWAS summary stats in gz format\n",
    "parameter: gwas_sumstats = path \n",
    "input: eqtl_sumstats, gwas_sumstats\n",
    "output: f\"{cwd:a}/{eqtl_sumstats:bn}.standardized.gz\", f\"{cwd:a}/{gwas_sumstats:bn}.standardized.gz\"\n",
    "R: expand = \"${ }\"\n",
    "\n",
    "    ###\n",
    "    # functions\n",
    "    ###\n",
    "\n",
    "    allele.qc = function(a1,a2,ref1,ref2) {\n",
    "        # a1 and a2 are the first data-set\n",
    "        # ref1 and ref2 are the 2nd data-set\n",
    "        # Make all the alleles into upper-case, as A,T,C,G:\n",
    "            a1 = toupper(a1)\n",
    "            a2 = toupper(a2)\n",
    "            ref1 = toupper(ref1)\n",
    "            ref2 = toupper(ref2)\n",
    "        # Strand flip, to change the allele representation in the 2nd data-set\n",
    "        strand_flip = function(ref) {\n",
    "            flip = ref\n",
    "            flip[ref == \"A\"] = \"T\"\n",
    "            flip[ref == \"T\"] = \"A\"\n",
    "            flip[ref == \"G\"] = \"C\"\n",
    "            flip[ref == \"C\"] = \"G\"\n",
    "            flip\n",
    "        }\n",
    "        flip1 = strand_flip(ref1)\n",
    "        flip2 = strand_flip(ref2)\n",
    "        snp = list()\n",
    "        # Remove strand ambiguous SNPs (scenario 3)\n",
    "        snp[[\"keep\"]] = !((a1==\"A\" & a2==\"T\") | (a1==\"T\" & a2==\"A\") | (a1==\"C\" & a2==\"G\") | (a1==\"G\" & a2==\"C\"))\n",
    "        # Remove non-ATCG coding\n",
    "        snp[[\"keep\"]][ a1 != \"A\" & a1 != \"T\" & a1 != \"G\" & a1 != \"C\" ] = F\n",
    "        snp[[\"keep\"]][ a2 != \"A\" & a2 != \"T\" & a2 != \"G\" & a2 != \"C\" ] = F\n",
    "        # as long as scenario 1 is involved, sign_flip will return TRUE\n",
    "        snp[[\"sign_flip\"]] = (a1 == ref2 & a2 == ref1) | (a1 == flip2 & a2 == flip1)\n",
    "        # as long as scenario 2 is involved, strand_flip will return TRUE\n",
    "        snp[[\"strand_flip\"]] = (a1 == flip1 & a2 == flip2) | (a1 == flip2 & a2 == flip1)\n",
    "        # remove other cases, eg, tri-allelic, one dataset is A C, the other is A G, for example.\n",
    "        exact_match = (a1 == ref1 & a2 == ref2) \n",
    "        snp[[\"keep\"]][!(exact_match | snp[[\"sign_flip\"]] | snp[[\"strand_flip\"]])] = F\n",
    "        return(snp)\n",
    "    }\n",
    "\n",
    "    # Extract information from RData\n",
    "    eqtl.split = function(eqtl){\n",
    "      rows = length(eqtl)\n",
    "      chr = vector(length = rows)\n",
    "      pos = vector(length = rows)\n",
    "      a1 = vector(length = rows)\n",
    "      a2 = vector(length = rows)\n",
    "      for (i in 1:rows){\n",
    "        split1 = str_split(eqtl[i], \":\")\n",
    "        split2 = str_split(split1[[1]][2], \"_\")\n",
    "        chr[i]= split1[[1]][1]\n",
    "        pos[i] = split2[[1]][1]\n",
    "        a1[i] = split2[[1]][2]\n",
    "        a2[i] = split2[[1]][3]\n",
    "\n",
    "      }\n",
    "      eqtl.df = data.frame(eqtl,chr,pos,a1,a2)\n",
    "    }\n",
    "\n",
    "    remove.dup = function(df){\n",
    "      df = df %>% arrange(PosGRCh37, -N)\n",
    "      df = df[!duplicated(df$PosGRCh37),]\n",
    "      return(df)\n",
    "    }\n",
    "  \n",
    "    ###\n",
    "    # Code\n",
    "    ###\n",
    "    # eqtl\n",
    "    load(file.choose())\n",
    "    eqtl = gene.name\n",
    "\n",
    "    #ld\n",
    "    ld = readRDS(file.choose())\n",
    "    # initial filter of gwas variants that are in eqtl\n",
    "    gwas_filter = gwas[which(gwas$id %in% var),]\n",
    "\n",
    "    # create eqtl df\n",
    "    eqtl.df = eqtl.split(var)\n",
    "\n",
    "    # allele flip\n",
    "    f_gwas = gwas %>% filter(chr %in% eqtl.df$chr & PosGRCh37 %in% eqtl.df$pos)\n",
    "    eqtl.df.f = eqtl.df %>% filter(pos %in% f_gwas$PosGRCh37)\n",
    "\n",
    "    # check if there are duplicate pos\n",
    "    length(unique(f_gwas$PosGRCh37))\n",
    "\n",
    "    # multiple snps with same pos\n",
    "    dup.pos = f_gwas %>% group_by(PosGRCh37) %>% filter(n() > 1) \n",
    "\n",
    "    f_gwas = remove.dup(f_gwas)\n",
    "\n",
    "    qc = allele.qc(f_gwas$testedAllele, f_gwas$otherAllele, eqtl.df.f$a1, eqtl.df.f$a2)\n",
    "    keep = as.data.frame(qc$keep)\n",
    "    sign = as.data.frame(qc$sign_flip)\n",
    "    strand = as.data.frame(qc$strand_flip)\n",
    "\n",
    "    # sign flip\n",
    "    f_gwas$z[qc$sign_flip] = -1 * f_gwas$z[qc$sign_flip]\n",
    "    f_gwas$testedAllele[qc$sign_flip] = eqtl.df.f$a1[qc$sign_flip]\n",
    "    f_gwas$otherAllele[qc$sign_flip] = eqtl.df.f$a2[qc$sign_flip]\n",
    "\n",
    "    f_gwas$testedAllele[qc$strand_flip] = eqtl.df.f$a1[qc$strand_flip]\n",
    "    f_gwas$otherAllele[qc$strand_flip] = eqtl.df.f$a2[qc$strand_flip]\n",
    "\n",
    "    # remove ambigiuous \n",
    "    if ( sum(!qc$keep) > 0 ) {\n",
    "      eqtl.df.f = eqtl.df.f[qc$keep,]\n",
    "      f_gwas = f_gwas[qc$keep,]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021694e2-2b2f-4396-94af-7c1a87dd42ce",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Extract common SNPS between the summary statistics and LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c03598-dbfe-4d63-aaf2-5818700b132f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[eqtl_1, gwas_1 (filter LD file and sumstat file)]\n",
    "parameter: sumstat_file = path\n",
    "# LD and region information: chr, start, end, LD file\n",
    "paramter: ld_region = path\n",
    "input: sumstat_file, for_each = 'ld_region'\n",
    "output: f\"{cwd:a}/{sumstat_file:bn}_{region[0]}_{region[1]}_{region[2]}.z.rds\",\n",
    "        f\"{cwd:a}/{sumstat_file:bn}_{region[0]}_{region[1]}_{region[2]}.ld.rds\"\n",
    "R:\n",
    "    # FIXME: need to filter both ways for sumstats and for LD\n",
    "    # lds filtered\n",
    "  \n",
    "    eqtl_id = which(var %in% eqtl.df.f$eqtl)\n",
    "    ld_f = ld[eqtl_id, eqtl_id]\n",
    "\n",
    "    # ld missing\n",
    "    miss = which(is.na(ld_f), arr.ind=TRUE)\n",
    "    miss_r = unique(as.data.frame(miss)$row)\n",
    "    miss_c = unique(as.data.frame(miss)$col)\n",
    "\n",
    "    total_miss = unique(union(miss_r,miss_c))\n",
    "    # FIXME: LD should not have missing data if properly processed by our pipeline\n",
    "    # In the future we should throw an error when it happens\n",
    "\n",
    "    if (length(total_miss)!=0){\n",
    "    ld_f2 = ld_f[-total_miss,]\n",
    "    ld_f2 = ld_f2[,-total_miss]\n",
    "    dim(ld_f2)\n",
    "    }else{ld_f2 = ld_f}\n",
    "    \n",
    "    f_gwas.f = f_gwas %>% filter(id %in% eqtl_id.f$eqtl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd0b91-5197-483a-8f36-a07be6c905d0",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: fine-mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d8570e-a47f-4264-acf4-51f4d77d3d73",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[eqtl_2, gwas_2 (finemapping)]\n",
    "# FIXME: RDS file should have included region information\n",
    "output: f\"{_input[0]:nn}.susieR.rds\", f\"{_input[0]:nn}.susieR_plot.rds\"\n",
    "R:\n",
    "    susie_results = susieR::susie_rss(z = f_gwas.f$z,R = ld_f2, check_prior = F)\n",
    "    susieR::susie_plot(susie_results,\"PIP\")\n",
    "    susie_results$z = f_gwas.f$z\n",
    "    susieR::susie_plot(susie_results,\"z_original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371b15b-eb5c-4838-8726-813e4db123fa",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: fine-mapping results processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4b0b8-60d8-43f2-ae8d-363f005e1c2a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Construct eQTL annotation file using eQTL SNP PIPs and credible sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a5f91-fcae-4588-9246-be30453e9bc2",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[eqtl_3 (create signal cluster using CS)]\n",
    "output: f\"{_input[0]:nn}.enloc_annot.gz\"\n",
    "R:\n",
    "    cs = eqtl[[\"sets\"]][[\"cs\"]][[\"L1\"]]\n",
    "    o_id = which(var %in% eqtl_id.f$eqtl)\n",
    "    pip = eqtl$pip[o_id]\n",
    "    eqtl_annot = cbind(eqtl_id.f, pip) %>% mutate(gene = gene.name,cluster = -1, cluster_pip = 0, total_snps = 0)\n",
    "\n",
    "    for(snp in cs){\n",
    "      eqtl_annot$cluster[snp] = 1\n",
    "      eqtl_annot$cluster_pip[snp] = eqtl[[\"sets\"]][[\"coverage\"]]\n",
    "       eqtl_annot$total_snps[snp] = length(cs)\n",
    "    }\n",
    "\n",
    "    eqtl_annot3 = eqtl_annot %>% filter(cluster != -1)%>% \n",
    "      mutate(annot = sprintf(\"%s:%d@=%e[%e:%d]\",gene,cluster,pip,cluster_pip,total_snps)) %>%\n",
    "      select(c(chr,pos,eqtl,a1,a2,annot))\n",
    "\n",
    "    # FIXME: write to a zip file\n",
    "    write.table(eqtl_annot, file = \"eqtl.annot.txt\", col.names = T, row.names = F, quote = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae8398-c471-4c0a-8cb9-f383ae29534c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Export GWAS PIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288c230-2623-402e-aeba-2bb02706a649",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[gwas_3 (format PIP into enloc GWAS input)]\n",
    "output: f\"{_input[0]:nn}.enloc_gwas.gz\"\n",
    "R:\n",
    "    gwas.annot = cbind(f_gwas.f,susie_results$pip)\n",
    "    write.table(gwas.annot, file = \"gwas.pip.txt\", col.names = F, row.names = F, quote = F)\n",
    "bash:\n",
    "    perl format2torus.pl gwas.pip.txt | gzip --best > gwas.pip.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d021f1-da65-4c1e-aad4-fa48961e9f81",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: Colocalization with FastEnloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922563a-de20-42c9-8b8b-bc0fea11b787",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[enloc]\n",
    "# eQTL summary statistics as a list of RData\n",
    "# FIXME: to replace later\n",
    "parameter: eqtl_pip = path \n",
    "# GWAS summary stats in gz format\n",
    "parameter: gwas_pip = path \n",
    "input: eqtl_pip, gwas_pip\n",
    "output: f\"{cwd:a}/{eqtl_pip:bnn}.{gwas_pip:bnn}.xx.gz\"\n",
    "bash:\n",
    "    fastenloc -eqtl eqtl.annot.txt.gz -gwas gwas.pip.txt.gz "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
