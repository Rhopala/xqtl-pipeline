{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "weird-option",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# RNA-seq Calling \n",
    "\n",
    "This pipeline aims to call the RNA-seq data (Step 1 to 4) as well as transcript quantification (Step 5) from original `fastq.gz` data. The whole pipeline is aligned with [GTEx](https://github.com/broadinstitute/gtex-pipeline/blob/master/TOPMed_RNAseq_pipeline.md). Please refer two [this page](https://github.com/broadinstitute/gtex-pipeline/blob/master/TOPMed_RNAseq_pipeline.md) for detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-carolina",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Methods overview\n",
    "\n",
    "![RNA quantification pipeline](../../../../_images/rna_quantification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-grain",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Setup and global parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-tissue",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# The output directory for generated files. MUST BE FULL PATH\n",
    "parameter: wd = path(\"./\")\n",
    "cwd = wd\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "\n",
    "# Raw data:\n",
    "parameter: fastq1_raw = path\n",
    "parameter: fastq2_raw = path\n",
    "fastq_raw = [fastq1_raw,fastq2_raw]\n",
    "# Sample id, name of the analysis?\n",
    "parameter: sample_id = str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "above-highway",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run bulk_expression.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  STAR_indexing\n",
      "  RMES_indexing\n",
      "  RNA_qc\n",
      "  Remove_adaptor\n",
      "  STAR_align\n",
      "  Picard_QC\n",
      "  RNA_QC\n",
      "  RSEM\n",
      "\n",
      "Global Workflow Options:\n",
      "  --wd VAL (as path, required)\n",
      "                        The output directory for generated files. MUST BE FULL\n",
      "                        PATH\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16384\n",
      "                        Memory expected\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --container-rna-calling VAL (as str, required)\n",
      "                        Software container option\n",
      "  --STAR-index VAL (as path, required)\n",
      "                        The directory for STAR index\n",
      "  --RMES-index VAL (as path, required)\n",
      "                        The directory for RMES index\n",
      "  --fastq1-raw VAL (as path, required)\n",
      "                        Raw data:\n",
      "  --fastq2-raw VAL (as path, required)\n",
      "  --sample-id VAL (as path, required)\n",
      "                        Sample id\n",
      "\n",
      "Sections\n",
      "  STAR_indexing:\n",
      "    Workflow Options:\n",
      "      --STAR-index-dir VAL (as path, required)\n",
      "                        Output directory:\n",
      "      --gtf VAL (as path, required)\n",
      "                        Reference genome\n",
      "      --fasta VAL (as path, required)\n",
      "      --sjdbOverhang VAL (as int, required)\n",
      "                        Length:\n",
      "  RMES_indexing:\n",
      "    Workflow Options:\n",
      "      --RMES-index-dir VAL (as path, required)\n",
      "                        Output directory:\n",
      "      --gtf VAL (as path, required)\n",
      "                        Reference genome\n",
      "      --fasta VAL (as path, required)\n",
      "  RNA_qc:\n",
      "  Remove_adaptor:\n",
      "    Workflow Options:\n",
      "      --soft-dir VAL (as path, required)\n",
      "                        Path to the software:\n",
      "      --adapter VAL (as str, required)\n",
      "                        Path to the reference adaptors:\n",
      "  STAR_align:\n",
      "    Workflow Options:\n",
      "      --fastq1-clean VAL (as path, required)\n",
      "  Picard_QC:\n",
      "    Workflow Options:\n",
      "      --STAR-bam VAL (as path, required)\n",
      "                        OUtput from STAR:\n",
      "  RNA_QC:\n",
      "    Workflow Options:\n",
      "      --STAR-bam VAL (as path, required)\n",
      "                        Output from STAR:\n",
      "      --gtf VAL (as path, required)\n",
      "                        Reference genome\n",
      "  RSEM:\n"
     ]
    }
   ],
   "source": [
    "sos run bulk_expression.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-flexibility",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Step 0.1: (Optional) Generating indexing file for `STAR` \n",
    "This step generate the indexing file for STAR alignment. This file just need to generate once and can be re-used. \n",
    "\n",
    "### Step Inputs:\n",
    "* `STAR_index_dir`: a path to the output.\n",
    "* `gtf` and `fasta`: path to reference sequence. Both of them needs to be unzipped\n",
    "* `sjdbOverhang`: specifies the length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database. Ideally, this length should be equal to the ReadLength-1, where ReadLength is the length of the reads.\n",
    "\n",
    "### Step Output:\n",
    "* Indexing file stored in `STAR_index_dir`, which will be used by `STAR`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-poultry",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Step 0.2: (Optional) Generating indexing file for `RSEM`\n",
    "This step generate the indexing file for `RSEM`. This file just need to generate once.\n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `RSEM_index_dir`: a path to the output.\n",
    "* `gtf` and `fasta`: path to reference sequence.\n",
    "* `sjdbOverhang`: specifies the length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database. Ideally, this length should be equal to the ReadLength-1, where ReadLength is the length of the reads.\n",
    "\n",
    "### Step Outputs:\n",
    "* Indexing file stored in `RSEM_index_dir`, which will be used by `RSEM`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-today",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 0.3: QC before alignment\n",
    "**FIXME** This software need to be install. \n",
    "\n",
    "This step utilize `fastqc` and will generate two QC report in `html` format\n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `fastq1_raw` and `fastq2_raw`: paths to original `fastq.gz` file.\n",
    "\n",
    "### Step Outputs:\n",
    "* Two `html` file for QC report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cardiac-collective",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[fastqc_report]\n",
    "input: for_each = \"fastq_raw\"\n",
    "output: f'{cwd}/{_fastq_raw:bnn}_fastqc.html',f'{cwd}/{_fastq_raw:bnn}_fastqc/fastqc_data.txt' \n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container=container\n",
    "    fastqc ${_fastq_raw} -o ${_output[0]:d}\n",
    "    unzip ${_output[0]:n}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-immigration",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 1: Remove adaptor through `Trimmomatic`\n",
    "Documentation: [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic)\n",
    "\n",
    "**FIXME** This step is form the workflow at Boston. and not in GTEx pipeline. Also, this software need to be install. \n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `fastq1_raw` and `fastq2_raw`: paths to original `fastq.gz` file.\n",
    "* `soft_dir`: directory for the software\n",
    "* `adapter`: **string** for the adapter reference file.\n",
    "\n",
    "### Step Outputs:\n",
    "* Two paired `fastq.gz` file for alignment\n",
    "* Two unpaired `fastq.gz` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wired-release",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[Remove_adaptor]\n",
    "# Path to the software:\n",
    "parameter: soft_dir = path\n",
    "# Path to the reference adaptors:\n",
    "parameter: adapter_file = \"TruSeq3-PE.fa\"\n",
    "parameter: maximum_mismatch_count = 2\n",
    "parameter: palindrome_clip_threshold = 30\n",
    "parameter: simple_clip_threshold = 10\n",
    "# Other parameters (i.e. leading, trailing ... )\n",
    "input: fastq1_raw, fastq2_raw\n",
    "output: fq_1 = f'{wd}/{sample_id}_paired_{_input[0]:bn}.gz',\n",
    "        fq_1_up = f'{wd}/{sample_id}_unpaired_{_input[0]:bn}.gz',\n",
    "        fq_2 = f'{wd}/{sample_id}_paired_{_input[1]:bn}.gz',\n",
    "        fq_2_up = f'{wd}/{sample_id}_unpaired_{_input[1]:bn}.gz'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '10G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    java -jar ${soft_dir}/trimmomatic-0.39.jar PE -threads ${numThreads} \\\n",
    "                            ${_input[0]} \\\n",
    "                            ${_input[1]} \\\n",
    "                            ${_output[0]} \\\n",
    "                            ${_output[1]} \\\n",
    "                            ${_output[2]} \\\n",
    "                            ${_output[3]} \\\n",
    "                            ILLUMINACLIP:${adapter_file}:${maximum_mismatch_count}:${palindrome_clip_threshold}:${simple_clip_threshold} \\\n",
    "                            LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789021f8-e848-44e5-af93-b88939ba98ab",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "retained-france",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 2: Alignment through `STAR`\n",
    "\n",
    "Documentation : [STAR](https://github.com/alexdobin/STAR) and [Script in docker](https://github.com/broadinstitute/gtex-pipeline/blob/master/rnaseq/src/run_STAR.py)\n",
    "\n",
    "This step is the main step for `STAR` alignment. \n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `fastq1_clean` and `fastq2_clean`: paths to clean `fastq.gz` file from Step 1.\n",
    "* `STAR_index`: directory for the STAR aligment index\n",
    "\n",
    "### Step Outputs:\n",
    "* bam file output `${wd}/{sample_id}.Aligned.sortedByCoord.out.bam`, will be used in step 3 and 4\n",
    "* bam file output `${wd}/{sample_id}.Aligned.toTranscriptome.out.bam`, will be used in step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "higher-signal",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[STAR_align]\n",
    "# STAR indexing file\n",
    "parameter: STAR_index = path\n",
    "# Alignment parameter\n",
    "parameter: outFilterMultimapNmax = 20 \n",
    "parameter: alignSJoverhangMin = 8 \n",
    "parameter: alignSJDBoverhangMin = 1 \n",
    "parameter: outFilterMismatchNmax = 999 \n",
    "parameter: outFilterMismatchNoverLmax = 0.1\n",
    "parameter: alignIntronMin = 20 \n",
    "parameter: alignIntronMax = 1000000 \n",
    "parameter: alignMatesGapMax = 1000000 \n",
    "parameter: outFilterType =  \"BySJout\" \n",
    "parameter: outFilterScoreMinOverLread = 0.33 \n",
    "parameter: outFilterMatchNminOverLread = 0.33 \n",
    "parameter: limitSjdbInsertNsj = 1200000 \n",
    "parameter: outSAMstrandField = \"intronMotif\" \n",
    "parameter: outFilterIntronMotifs = \"None\" \n",
    "parameter: alignSoftClipAtReferenceEnds = \"Yes\" \n",
    "parameter: quantMode = \"TranscriptomeSAM GeneCounts\" \n",
    "parameter: outSAMattrRGline = \"ID:rg1 SM:sm1\" \n",
    "parameter: outSAMattributes = \"NH HI AS nM NM ch\" \n",
    "parameter: chimSegmentMin = 15 \n",
    "parameter: chimJunctionOverhangMin = 15 \n",
    "parameter: chimOutType =  \"Junctions WithinBAM SoftClip\" \n",
    "parameter: chimMainSegmentMultNmax = 1 \n",
    "\n",
    "input: output_from(\"Remove_adaptor\")[\"fq_1\"],output_from(\"Remove_adaptor\")[\"fq_2\"]\n",
    "output: cord_bam = f'{wd}/{sample_id}.Aligned.sortedByCoord.out.bam',\n",
    "        trans_bam = f'{wd}/{sample_id}.Aligned.toTranscriptome.out.bam'\n",
    "\n",
    "task: trunk_workers = 1, walltime = '24h', mem = \"40G\", cores = numThreads\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    run_STAR.py \\\n",
    "        ${STAR_index} ${_input[0]} ${_input[1]} ${sample_id} \\\n",
    "        --output_dir ${wd} \\\n",
    "        --outFilterMultimapNmax ${outFilterMultimapNmax} \\\n",
    "        --alignSJoverhangMin ${alignSJoverhangMin} \\\n",
    "        --alignSJDBoverhangMin ${alignSJDBoverhangMin} \\\n",
    "        --outFilterMismatchNmax ${outFilterMismatchNmax} \\\n",
    "        --outFilterMismatchNoverLmax ${outFilterMismatchNoverLmax} \\\n",
    "        --alignIntronMin ${alignIntronMin} \\\n",
    "        --alignIntronMax ${alignIntronMax} \\\n",
    "        --alignMatesGapMax ${alignMatesGapMax} \\\n",
    "        --outFilterType ${outFilterType} \\\n",
    "        --outFilterScoreMinOverLread ${outFilterScoreMinOverLread} \\\n",
    "        --outFilterMatchNminOverLread ${outFilterMatchNminOverLread} \\\n",
    "        --limitSjdbInsertNsj ${limitSjdbInsertNsj} \\\n",
    "        --outSAMstrandField ${outSAMstrandField} \\\n",
    "        --outFilterIntronMotifs ${outFilterIntronMotifs} \\\n",
    "        --alignSoftClipAtReferenceEnds ${alignSoftClipAtReferenceEnds} \\\n",
    "        --quantMode ${quantMode} \\\n",
    "        --outSAMattrRGline ${outSAMattrRGline} \\\n",
    "        --outSAMattributes ${outSAMattributes} \\\n",
    "        --chimSegmentMin ${chimSegmentMin} \\\n",
    "        --chimJunctionOverhangMin ${chimJunctionOverhangMin} \\\n",
    "        --chimOutType ${chimOutType} \\\n",
    "        --chimMainSegmentMultNmax ${chimMainSegmentMultNmax} \\\n",
    "        --threads ${numThreads}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-landing",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 3: Mark duplicates reads through `Picard`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-regular",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Documentation : [MarkDuplicates](https://github.com/alexdobin/STAR) and [Script in docker](https://github.com/broadinstitute/gtex-pipeline/blob/master/rnaseq/src/run_MarkDuplicates.py)\n",
    "\n",
    "This step is the first QC step after `STAR` alignment. This step maily remove duplications in `bam` file output by STAR.\n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `STAR_bam`: path to the output in Step 2.\n",
    "\n",
    "### Step Outputs:\n",
    "\n",
    "* A new `.bam` file with duplication  marked with the hexadecimal value of `0x0400`, which corresponds to a decimal value of 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "correct-season",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Picard_QC]\n",
    "input: output_from(\"STAR_align\")[\"cord_bam\"]\n",
    "output: f'{wd}/${sample_id}.Aligned.sortedByCoord.out.patched.md.bam'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        run_MarkDuplicates.py ${_input} ${sample_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-affair",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 4: Post aligment QC through `RNA-SeQC`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-expert",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Documentation : [RNA-SeQC](https://github.com/getzlab/rnaseqc) and [Script in docker](https://github.com/broadinstitute/gtex-pipeline/blob/master/rnaseq/src/run_rnaseqc.py)\n",
    "\n",
    "**FIXME**\n",
    "\n",
    "This step is second QC step after `STAR` alignment. \n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `QC_bam`: path to the output in Step 3.\n",
    "* `gtf`: reference genome `.gtf` file \n",
    "\n",
    "### Step Outputs:\n",
    "need to fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pacific-matthew",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[RNA_QC]\n",
    "# Output from STAR:\n",
    "parameter: QC_bam = path\n",
    "# Reference genome\n",
    "parameter: gtf = path\n",
    "\n",
    "input: output_from(\"Picard_QC\")\n",
    "bash: container=container, expand= \"${ }\"\n",
    "    python3 run_rnaseqc.py \\\n",
    "        ${gtf}\n",
    "        ${_input} \\\n",
    "        ${sample_id} \\\n",
    "        --stranded rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-dragon",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 5: Quantify expression through `RSEM`\n",
    "\n",
    "Documentation : [RSEM](https://deweylab.github.io/RSEM/rsem-calculate-expression.html) and [Script in docker](https://github.com/broadinstitute/gtex-pipeline/blob/master/rnaseq/src/run_RSEM.py)\n",
    "\n",
    "This step generate the expression matrix from STAR output. Estimate gene and isoform expression from RNA-Seq data are generated.\n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `STAR_tras`: path to the output in Step 2.\n",
    "* `RSEM_index`: path to RSEM index\n",
    "\n",
    "### Step Outputs:\n",
    "need to fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "knowing-egyptian",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[RSEM]\n",
    "parameter: RSEM_index = path\n",
    "input: output_from(\"STAR_align\")[\"trans_bam\"]\n",
    "output: f'{wd}/RSEM_output/final_log'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    run_RSEM.py \\\n",
    "        --max_frag_len 1000 \\\n",
    "        --estimate_rspd true \\\n",
    "        --is_stranded true \\\n",
    "        --threads ${numThreads} \\\n",
    "        ${RSEM_index} ${_input:a} ${sample_id} -o ${_output:d}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
