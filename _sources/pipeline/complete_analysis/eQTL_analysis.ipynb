{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "common-chemistry",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Bulk RNA-seq eQTL analysis\n",
    "\n",
    "This notebook provide a master control on the XQTL workflow so it can works on multiple data collection as proposed.\n",
    "Input:\n",
    "    A recipe file,each row is a data collection and with the following column:\n",
    "    \n",
    "    Theme\n",
    "        name of dataset, must be different, each uni_study analysis will be performed in a folder named after each, meta analysis will be performed in a folder named as {study1}_{study2}\n",
    "            \n",
    "        The column name must contain the # and be the first column\n",
    "    \n",
    "    genotype_list\n",
    "        {Path to file}\n",
    "    \n",
    "    molecular_pheno\n",
    "        {Path to file}\n",
    "    region_list (list of regions to be analzed)\n",
    "        {Path to file}\n",
    "    \n",
    "    covariate_file\n",
    "        {Path to file}\n",
    "    \n",
    "    factor_analysis_opt\n",
    "        \"APEX\" vs \"PEER\" for factor analysis\n",
    "    \n",
    "    LD options:\n",
    "        \"In-sample\" LD vs {path to reference panel}\n",
    "    \n",
    "    QTL_tool_option\n",
    "        \"APEX\" vs \"TensorQTL\" for QTL association\n",
    "    \n",
    "    QTL_analysis_option\n",
    "        {Int for cis window} vs \"trans\"\n",
    "    \n",
    "    Populations\n",
    "        The populations from which of the samples was drawn\n",
    "    \n",
    "    Conditions:\n",
    "        The nature of molecular phenotype\n",
    "    \n",
    "    ### note: Only data collection from the same Populations and conditions will me merged to perform Fix effect meta analysis\n",
    "    \n",
    "Output:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-trading",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Generation of MWE\n",
    "This is the code to generate the mwe recipe and LD_recipe on csg cluster\n",
    "\n",
    "**FIXME: Hao, I'm thinking that for this configuration file we should not speicify any parameter (eg `cis_windows` below), but only file locations and workflow names. the outcome of running this should also be that instead of running anything, we write the sequence of commands to execute to a `sh` file (with automatic comment strings `#` to separate the sections) for people to run on their own, so they will have better control over everything. Is there an issue with this plan? (please slack me for discussions on this if necessary). Otherwise, let's focus first on finishing up the modules and worry about this the last?**\n",
    "\n",
    "**FIXME: Also, this file should be those that reproduces exactly the official default Brain xQTL consortium analysis. That is why I would rather have it per xQTL type even if there will be duplicated lines of contents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-financing",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "Recipe_temp = pd.DataFrame( {\"Theme\" : [\"AC\",\"DLPFC\",\"PCC\"] ,\n",
    "                \"genotype_list\" : [\"/home/hs3163/GIT/ADSPFG-xQTL/MWE/mwe_genotype_list\",\n",
    "                   \"/home/hs3163/GIT/ADSPFG-xQTL/MWE/mwe_genotype_list\",\n",
    "                   \"/home/hs3163/GIT/ADSPFG-xQTL/MWE/mwe_genotype_list\"],\n",
    "                \"molecular_pheno\" : [\"/home/hs3163/Project/Rosmap/data/gene_exp/AC/geneTpmResidualsAgeGenderAdj_rename.txt\",\n",
    "                     \"/home/hs3163/Project/Rosmap/data/gene_exp/DLPFC/geneTpmResidualsAgeGenderAdj_rename.txt\",\n",
    "                     \"/home/hs3163/Project/Rosmap/data/gene_exp/PCC/geneTpmResidualsAgeGenderAdj_rename.txt\"],\n",
    "                \"region_list\" : [\"~/GIT/ADSPFG-xQTL/MWE/mwe_region\",\n",
    "                \"~/GIT/ADSPFG-xQTL/MWE/mwe_region\",\n",
    "                \"~/GIT/ADSPFG-xQTL/MWE/mwe_region\"] ,\n",
    "                \"covariate_file\" : [\"/home/hs3163/GIT/ADSPFG-xQTL/MWE/MWE.cov\",\"/home/hs3163/GIT/ADSPFG-xQTL/MWE/MWE.cov\",\"/home/hs3163/GIT/ADSPFG-xQTL/MWE/MWE.cov\"],\n",
    "                \"factor_analysis_opt\" : [\"APEX\",\"APEX\",\"APEX\"],\n",
    "                \"LD_Recipe\": [\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\",\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\",\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\"],\n",
    "                \"QTL_tool_option\" : [\"APEX\",\"APEX\",\"APEX\"],\n",
    "                \"QTL_analysis_option\" : [\"cis\",\"cis\",\"cis\"],\n",
    "                \"cis_windows\" : [500000,500000,5000000],\n",
    "                \"Metal\" : [\"T\",\"T\",\"F\"]}).to_csv(\"/home/hs3163/GIT/ADSPFG-xQTL/MWE/mwe_recipe_example\",\"\\t\")\n",
    "\n",
    "        ### note: Only data collection from the same Populations and conditions will me merged to perform Fix effect meta analysis\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24938f6a-4c72-42d5-92a3-9ae4ec7200d2",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame( {\"Theme\" : [\"AC\",\"DLPFC\",\"PCC\"] ,\n",
    "                \"genotype_list\" : [\" /mnt/mfs/statgen/ROSMAP_xqtl/Rosmap_wgs_genotype_list.txt\",\n",
    "                   \" /mnt/mfs/statgen/ROSMAP_xqtl/Rosmap_wgs_genotype_list.txt\",\n",
    "                   \" /mnt/mfs/statgen/ROSMAP_xqtl/Rosmap_wgs_genotype_list.txt\"],\n",
    "                \"molecular_pheno\" : [\"/home/hs3163/Project/Rosmap/data/gene_exp/AC/geneTpmResidualsAgeGenderAdj_rename.txt\",\n",
    "                     \"/home/hs3163/Project/Rosmap/data/gene_exp/DLPFC/geneTpmResidualsAgeGenderAdj_rename.txt\",\n",
    "                     \"/home/hs3163/Project/Rosmap/data/gene_exp/PCC/geneTpmResidualsAgeGenderAdj_rename.txt\"],\n",
    "                \"region_list\" : [\"/home/hs3163/Project/Rosmap/data/gene_exp/AC/geneTpmResidualsAgeGenderAdj_rename_region_list.txt\",\n",
    "                \"/home/hs3163/Project/Rosmap/data/gene_exp/AC/geneTpmResidualsAgeGenderAdj_rename_region_list.txt\",\n",
    "                \"/home/hs3163/Project/Rosmap/data/gene_exp/AC/geneTpmResidualsAgeGenderAdj_rename_region_list.txt\"] ,\n",
    "                \"covariate_file\" : [\"None\",\"None\",\"None\"],\n",
    "                \"factor_analysis_opt\" : [\"BiCV\",\"BiCV\",\"BiCV\"],\n",
    "                \"LD_Recipe\": [\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\",\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\",\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\"],\n",
    "                \"QTL_tool_option\" : [\"APEX\",\"APEX\",\"APEX\"],\n",
    "                \"QTL_analysis_option\" : [\"cis\",\"cis\",\"cis\"],\n",
    "                \"cis_windows\" : [500000,500000,500000],\n",
    "                \"Metal\" : [\"T\",\"T\",\"F\"]}).to_csv(\"/home/hs3163/GIT/xqtl-pipeline/ROSMAP_recipe_example\",\"\\t\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5fe2b4-c737-47f6-9989-dd49c77b9a6e",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "home/hs3163/GIT/xqtl-pipeline/ROSMAP_recipe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-stations",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"ld_file_prefix\" : [\"/mnt/mfs/statgen/neuro-twas/mv_wg/cache_arch/cache/geneTpmResidualsAgeGenderAdj_rename.\",\"/mnt/mfs/statgen/neuro-twas/mv_wg/cache_arch/cache/geneTpmResidualsAgeGenderAdj_rename.\"],\n",
    "               \"ld_file_surfix\" : [\".merged.ld.rds\",\".merged.ld.rds\"]}).to_csv(\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\",sep = \"\\t\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ae60f-1b30-49f9-ab46-a98fbb938d08",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/complete_analysis/eQTL_analysis.ipynb QTL \\\n",
    "    --recipe /home/hs3163/GIT/ADSPFG-xQTL/MWE/mwe_recipe_example \\\n",
    "    --wd ./ \\\n",
    "    --exe_dir \"/home/hs3163/GIT/xqtl-pipeline/pipeline/\" &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7db06-2f09-45f8-9359-a5809e7d68fe",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos dryrun /home/hs3163/GIT/xqtl-pipeline/pipeline/complete_analysis/eQTL_analysis.ipynb mash_to_vcf \\\n",
    "--recipe /home/hs3163/GIT/xqtl-pipeline/ROSMAP_recipe_example --wd ./ --exe_dir \"~/GIT/xqtl-pipeline/pipeline/\" -s build &\n",
    "\n",
    "nohup sos dryrun /home/hs3163/GIT/xqtl-pipeline/pipeline/complete_analysis/eQTL_analysis.ipynb phenotype_reformatting_by_gene \\\n",
    "--recipe /home/hs3163/GIT/xqtl-pipeline/ROSMAP_recipe_example --wd ./ --exe_dir \"~/GIT/xqtl-pipeline/pipeline/\" -s build &\n",
    "\n",
    "nohup sos dryrun /home/hs3163/GIT/xqtl-pipeline/pipeline/complete_analysis/eQTL_analysis.ipynb genotype_reformatting_per_gene \\\n",
    "--recipe /home/hs3163/GIT/xqtl-pipeline/ROSMAP_recipe_example --wd ./ --exe_dir \"~/GIT/xqtl-pipeline/pipeline/\" -s build &\n",
    "\n",
    "nohup sos dryrun /home/hs3163/GIT/xqtl-pipeline/pipeline/complete_analysis/eQTL_analysis.ipynb mixture_prior \\\n",
    "--recipe /home/hs3163/GIT/xqtl-pipeline/ROSMAP_recipe_example --wd ./ --exe_dir \"~/GIT/xqtl-pipeline/pipeline/\" -s build &\n",
    "\n",
    "\n",
    "nohup sos run ~/GIT/bioworkflows/GWAS/PCA.ipynb flashpca \\\n",
    "   --genoFile /mnt/mfs/statgen/xqtl_workflow_testing/ROSMAP/data_preprocessing/genotype/qc/PCC.mergrd.filtered.prune.unrelated.bed \\\n",
    "   --name PCC \\\n",
    "   --container_lmm /mnt/mfs/statgen/containers/xqtl_pipeline_sif/flashpcaR.sif \\\n",
    "   --cwd /mnt/mfs/statgen/xqtl_workflow_testing/demo/test_pca/ \\\n",
    "   -J 200 -q csg -c /home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml &\n",
    "\n",
    "nohup sos run ~/GIT/bioworkflows/GWAS/PCA.ipynb project_samples:1 \\\n",
    "   --genoFile /mnt/mfs/statgen/xqtl_workflow_testing/ROSMAP/data_preprocessing/genotype/qc/PCC.mergrd.filtered.prune.related.bed \\\n",
    "   --pca_model  /mnt/mfs/statgen/xqtl_workflow_testing/demo/test_pca/PCC.mergrd.filtered.prune.unrelated.PCC.pca.rds \\\n",
    "   --name PCC \\\n",
    "   --container_lmm /mnt/mfs/statgen/containers/xqtl_pipeline_sif/flashpcaR.sif \\\n",
    "   --cwd /mnt/mfs/statgen/xqtl_workflow_testing/demo/test_pca/ \\\n",
    "   -J 200 -q csg -c /home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-perfume",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Example for running the workflow\n",
    "This will run the workflow from via several submission and save the output to nohup.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-scroll",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512bace5-412d-4ac2-a685-79d9e4c240b3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "flying-emphasis",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Other example workflow:\n",
    "These command run each of the substep to test them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-station",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-latex",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "## The aforementioned input recipe\n",
    "parameter: recipe = path\n",
    "## Overall wd, the file structure of analysis is wd/[steps]/[sub_dir for each steps]\n",
    "parameter:  wd = path(\".\")\n",
    "## Diretory to the excutable\n",
    "parameter: exe_dir = path(\"~/GIT/ADSPFG-xQTL/workflow\")\n",
    "\n",
    "parameter: container = '/mnt/mfs/statgen/containers/twas_latest.sif'\n",
    "parameter: container_base_bioinfo = '/mnt/mfs/statgen/containers/xqtl_pipeline_sif/base-bioinfo.sif'\n",
    "parameter: container_apex = '/mnt/mfs/statgen/containers/xqtl_pipeline_sif/apex.sif'\n",
    "parameter: container_PEER = '/mnt/mfs/statgen/containers/xqtl_pipeline_sif/PEER.sif'\n",
    "parameter: container_TensorQTL = '/mnt/mfs/statgen/containers/xqtl_pipeline_sif/TensorQTL.sif'\n",
    "parameter: container_mvsusie = '/mnt/mfs/statgen/containers/twas_latest.sif'\n",
    "parameter: container_METAL = '/mnt/mfs/statgen/containers/xqtl_pipeline_sif/METAL.sif'\n",
    "parameter: container_flashpca = '/mnt/mfs/statgen/containers/xqtl_pipeline_sif/flashpcaR.sif'\n",
    "parameter: yml = \"/home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml\"\n",
    "import pandas as pd\n",
    "input_inv = pd.read_csv(recipe, sep = \"\\t\")\n",
    "Metal_theme = input_inv.query(\"Metal == 'T'\")[\"Theme\"].to_list()\n",
    "Metal_theme_str = \"-\".join(Metal_theme)\n",
    "Non_Metal_theme = input_inv.query(\"Metal != 'T'\")[\"Theme\"].to_list()\n",
    "Non_Metal_theme.append(Metal_theme_str)\n",
    "Theme_Prefix = \"_\".join(Non_Metal_theme)\n",
    "parameter: LD_Recipe  = path(input_inv[\"LD_Recipe\"][0])\n",
    "input_inv = input_inv.to_dict(\"records\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada369b-c34b-4d84-8844-d86f4c2c22cb",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Molecular Phenotype Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3e749-cfd2-4d3d-927f-a2b4092aaeeb",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "increasing-tract",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "### Molecular Phenotype Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a022e2-7e42-40fb-861f-a5a39222e11d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[Normalization]\n",
    "#import os\n",
    "#input: for_each = \"input_inv\"\n",
    "#skip_if( os.path.exists(_input_inv[\"molecular_pheno\"]))\n",
    "#output: f'{wd:a}/data_preprocessing/normalization/{name}.mol_phe.bed.gz'\n",
    "#bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "#    sos run $[exe_dir]/data_preprocessing/phenotype/GWAS_QC.ipynb output \\\n",
    "#        --counts_gct $[_input_inv[\"genecount_table\"]] \\\n",
    "#        --tpm_gct $[_input_inv[\"geneTpm_table\"]] \\\n",
    "#        --sample_participant_lookup $[_input_inv[\"sample_index\"]] \\\n",
    "#        --vcf_chr_list $[_input_inv[\"vcf_chr_list\"]] \\\n",
    "#        --container $[container_gtex] \\\n",
    "#        --name $[_input_inv[\"Theme\"]] \\\n",
    "#        --wd $[wd:a]/data_preprocessing/normalization/ \\\n",
    "#        --container $[container_base_bioinfo] \\\n",
    "#        -J 200 -q csg -c $[yml] &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afee56-a0a3-45ad-8d40-859b7091ca9d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[annotation]\n",
    "## Must be ran with internet connection\n",
    "import os\n",
    "input: for_each = \"input_inv\"\n",
    "output: f'{wd:a}/data_preprocessing/annotation/{_input_inv[\"Theme\"]}.{path(_input_inv[\"molecular_pheno\"]):bn}.annotated.bed.gz'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    sos run $[exe_dir]/data_preprocessing/phenotype/annotation.ipynb annotation \\\n",
    "        --molecular_pheno_whole $[_input_inv[\"molecular_pheno\"]] \\\n",
    "        --wd $[wd:a]/data_preprocessing/annotation  \\\n",
    "        --name $[_input_inv[\"Theme\"]] --container $[container_base_bioinfo]  -s build &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ca898-cecf-4322-aa23-945872eb2f8a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[phenotype_reformatting]\n",
    "input: output_from(\"residual_phenotype\"),group_with = \"input_inv\"\n",
    "output: per_chrom_pheno_list = f'{wd:a}/data_preprocessing/phenotype_reformat/{_input_inv[\"Theme\"]}.processed_phenotype.per_chrom.recipe',\n",
    "        pheno_mod = f'{wd:a}/data_preprocessing/phenotype_reformat/{_input_inv[\"Theme\"]}.for_pca.mol_phe.exp'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/data_preprocessing/phenotype/phenotype_formatting.ipynb reformat \\\n",
    "        --molecular_pheno_whole $[_input] \\\n",
    "        --region_list $[_input_inv[\"region_list\"]] \\\n",
    "        --wd $[wd:a]/data_preprocessing/phenotype_reformat/  \\\n",
    "        --name $[_input_inv[\"Theme\"]] --container $[container_base_bioinfo] \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d96be-9d29-4bd0-90b6-f916b764dd97",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### The reformatiing by gene is particularly lenghthy, so to avoid exceesive waiting time, it is set to be a seperate substep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026217e9-f93a-43c2-a5ce-deb7fcf0772e",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[phenotype_reformatting_by_gene]\n",
    "input: output_from(\"residual_phenotype\"),group_with = \"input_inv\"\n",
    "output: per_gene_pheno_list = f'{wd:a}/data_preprocessing/phenotype_reformat/{_input_inv[\"Theme\"]}.processed_phenotype.per_gene.recipe'        \n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/data_preprocessing/phenotype/phenotype_formatting.ipynb partition_by_gene \\\n",
    "        --molecular_pheno_whole $[_input] \\\n",
    "        --region_list $[_input_inv[\"region_list\"]] \\\n",
    "        --wd $[wd:a]/data_preprocessing/phenotype_reformat/  \\\n",
    "        --name $[_input_inv[\"Theme\"]] --container $[container_base_bioinfo] \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407394a5-bc1d-49b7-a420-863e0a34852d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Genotype Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971c211-4886-4fc8-9ea9-3b9b3d41524e",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[genotype_QC]\n",
    "input: for_each = \"input_inv\"\n",
    "output: merged_plink =  f'{wd:a}/data_preprocessing/genotype/qc/{_input_inv[\"Theme\"]}.mergrd.filtered.prune.bed',\n",
    "        unrelated = f'{wd:a}/data_preprocessing/genotype/qc/{_input_inv[\"Theme\"]}.mergrd.filtered.prune.unrelated.bed',\n",
    "        related = f'{wd:a}/data_preprocessing/genotype/qc/{_input_inv[\"Theme\"]}.mergrd.filtered.prune.related.bed'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/data_preprocessing/genotype/GWAS_QC.ipynb qc \\\n",
    "        --genotype_list $[_input_inv[\"genotype_list\"]] \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --container_lmm $[container_base_bioinfo] \\\n",
    "        --cwd $[wd:a]/data_preprocessing/genotype/qc/ \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5243075-b1f5-4723-91e4-73065e9aa5f8",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[genotype_reformatting]\n",
    "import pandas as pd\n",
    "input: output_from(\"genotype_QC\")[\"merged_plink\"], group_with = \"input_inv\"\n",
    "name = _input_inv[\"Theme\"]\n",
    "output: vcf_list = f'{wd}/data_preprocessing/genotype/{name}_per_chrom_vcf/{name}.vcf_chrom_list.txt',\n",
    "        per_chrom_plink_list = f'{wd}/data_preprocessing/genotype/{name}_per_chrom_plink/{name}.plink_chrom_list.txt'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/data_preprocessing/genotype/genotype_formatting.ipynb plink2vcf \\\n",
    "        --genoFile $[_input] \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --container $[container_base_bioinfo] \\\n",
    "        --region_list $[_input_inv[\"region_list\"]] \\\n",
    "        --wd $[wd:a]/data_preprocessing/genotype/ \\\n",
    "        -J 200 -q csg -c /home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml \n",
    "    \n",
    "    sos run $[exe_dir]/data_preprocessing/genotype/genotype_formatting.ipynb plink_by_chrom \\\n",
    "        --genoFile $[_input] \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --region_list $[_input_inv[\"region_list\"]] \\\n",
    "        --container $[container_base_bioinfo] \\\n",
    "        --wd $[wd:a]/data_preprocessing/genotype/ \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c5b831-2bea-42c8-9310-06105ad7ccc3",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### The reformatiing by gene is particularly lenghthy, so to avoid exceesive waiting time, it is set to be a seperate substep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f92718-d5ae-4082-8d9a-093234f05d4d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[genotype_reformatting_per_gene]\n",
    "import pandas as pd\n",
    "input: output_from(\"genotype_QC\")[\"merged_plink\"], group_with = \"input_inv\"\n",
    "name = _input_inv[\"Theme\"]\n",
    "output: per_gene_plink = f'{wd}/data_preprocessing/genotype/{name}_per_gene_plink/{name}.plink_gene_list.txt'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/data_preprocessing/genotype/genotype_formatting.ipynb plink_by_gene \\\n",
    "                --genoFile $[_input] \\\n",
    "                --name $[_input_inv[\"Theme\"]] \\\n",
    "                --region_list $[_input_inv[\"region_list\"]] \\\n",
    "                --container $[container_base_bioinfo] \\\n",
    "                --region_list $[_input_inv[\"region_list\"]] \\\n",
    "                --wd $[wd:a]/data_preprocessing/genotype/ \\\n",
    "                -J 2000 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e5c96-bd9d-40ea-a06f-e37bf4c18f0a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[LD]\n",
    "import pandas as pd\n",
    "input: output_from(\"genotype_reformatting\")[\"per_gene_plink\"],group_with = \"input_inv\"\n",
    "output: f'{wd}/data_preprocessing/genotype/LD/{_input_inv[\"Theme\"]}._LD_recipe'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "     sos run $[exe_dir]/data_preprocessing/genotype/LD.ipynb LD \\\n",
    "        --genotype_list $[_input] \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --container $[container_base_bioinfo] \\\n",
    "        --wd $[wd:a]/data_preprocessing/genotype/LD/ \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f3952-5a41-4901-90fc-8383596945e6",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[LD_Recipe]\n",
    "input: output_from(\"LD\"), group_by = \"all\"\n",
    "output: f'{wd:a}/data_preprocessing/genotype/LD/sumstat_list'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import pandas as pd\n",
    "    input_list = [$[_input:r,]]\n",
    "    ld_recipe = pd.read_csv(input_list[0],sep = \"\\t\")\n",
    "    for x in range(1,len(input_list)):\n",
    "        ld_recipe = ld_recipe.append(pd.read_csv(input_list[x],sep = \"\\t\"))\n",
    "    ld_recipe.to_csv(\"$[_output]\", index = 0 , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718f246-af77-413e-a49c-55a3400ebc00",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[GRM]\n",
    "import pandas as pd\n",
    "input: output_from(\"genotype_reformatting\")[\"per_chrom_plink_list\"],group_with = \"input_inv\"\n",
    "output: f'{wd}/data_preprocessing/genotype/grm/{_input_inv[\"Theme\"]}.grm_list.txt'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "     sos run $[exe_dir]/data_preprocessing/genotype/GRM.ipynb GRM \\\n",
    "        --genotype_list $[_input] \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --container $[container_base_bioinfo] \\\n",
    "        --wd $[wd:a]/data_preprocessing/genotype/grm/ \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bb5ca-79f3-474e-850d-f27a6aae8746",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59581248-4f24-4155-ae58-c388e9570eb8",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[factor]\n",
    "input: output_from(\"genotype_reformatting\")[\"vcf_list\"],output_from(\"annotation\"),group_with = \"input_inv\"\n",
    "output: f'{wd}/data_preprocessing/covariate/{_input_inv[\"Theme\"]}.{_input_inv[\"factor_analysis_opt\"]}.cov'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/data_preprocessing/covariate/$[_input_inv[\"factor_analysis_opt\"]]_factor.ipynb $[_input_inv[\"factor_analysis_opt\"]] \\\n",
    "        --molecular_pheno $[_input[1]] \\\n",
    "        --genotype_list $[_input[0]] \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --wd $[wd:a]/data_preprocessing/covariate/ \\\n",
    "        -J 200 -q csg -c $[yml] $[f'--covariate {_input_inv[\"covariate_file\"]}' if os.path.exists(_input_inv[\"covariate_file\"]) else f''] \\\n",
    "        --container $[container_apex if _input_inv[\"factor_analysis_opt\"] == \"BiCV\" else container_PEER] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c782d-e86c-4a2b-a08f-6e826815c982",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[residual_phenotype]\n",
    "input: output_from(\"factor\"), output_from(\"annotation\"),group_with = \"input_inv\"\n",
    "output: f'{wd}/data_preprocessing/phenotype/{_input_inv[\"Theme\"]}.mol_phe.resid.bed.gz'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/data_preprocessing/covariate/remove_covariates.ipynb Residual_Y  \\\n",
    "        --molecular_pheno_whole  $[_input[1]] \\\n",
    "        --factor $[_input[0]]  \\\n",
    "        --wd $[wd]/data_preprocessing/phenotype \\\n",
    "        --name $[_input_inv[\"Theme\"]] --container $[container_base_bioinfo] \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f82ab5-d801-4875-993e-4e124366dd63",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[pca]\n",
    "import pandas as pd\n",
    "input: output_from(\"genotype_QC\")[\"related\"],output_from(\"genotype_QC\")[\"unrelated\"],group_with = \"input_inv\"\n",
    "output: f'{wd}/data_preprocessing/covariate/pca/{_input[0]:bn}.{_input_inv[\"Theme\"]}.pca.projected.rds'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "     sos run $[exe_dir]/data_preprocessing/covariate/PCA.ipynb flashpca \\\n",
    "        --genoFile $[_input[1]] \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --container_lmm $[container_flashpca] \\\n",
    "        --cwd $[wd:a]/data_preprocessing/covariate/pca/ \\\n",
    "        -J 200 -q csg -c $[yml] \n",
    "    \n",
    "     sos run $[exe_dir]/data_preprocessing/covariate/PCA.ipynb project_samples:1 \\\n",
    "        --genoFile $[_input[0]] \\\n",
    "        --pca_model $[wd:a]/data_preprocessing/covariate/pca/$[_input[1]:bn].$[_input_inv[\"Theme\"]].pca.rds \\\n",
    "        --name $[_input_inv[\"Theme\"]] \\\n",
    "        --container_lmm $[container_flashpca] \\\n",
    "        --cwd $[wd:a]/data_preprocessing/covariate/pca/ \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51efa9-19a0-43c9-80d3-34cf84c5844a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[pca_factor_merge]\n",
    "import pandas as pd\n",
    "input: output_from(\"pca\"),output_from(\"factor\"),group_with = \"input_inv\"\n",
    "output: f'{wd}/data_preprocessing/covariate/{_input[1]:bn}.pca.cov'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "     sos run $[exe_dir]/data_preprocessing/covariate/merge_covariate.ipynb pca_factor_merge  \\\n",
    "        --factor_and_covariate $[_input[1]] \\\n",
    "        --PC $[_input[0]] \\\n",
    "        --container $[container_base_bioinfo] \\\n",
    "        --wd $[wd:a]/data_preprocessing/covariate/ \\\n",
    "        -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249fb1e-13e8-49a2-a110-cd37cbdcbb9b",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fourth-river",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## QTL associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-tragedy",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[QTL_1]\n",
    "input: output_from(\"pca_factor_merge\"),output_from(\"GRM\"),output_from(\"phenotype_reformatting\")[\"per_chrom_pheno_list\"],output_from(\"genotype_reformatting\")[\"vcf_list\"], output_from(\"genotype_reformatting\")[\"per_chrom_plink_list\"] ,group_with = \"input_inv\"\n",
    "output: f'{wd:a}/association_scan/{_input_inv[\"QTL_tool_option\"]}/{_input_inv[\"QTL_analysis_option\"]}/{_input_inv[\"Theme\"]}.{_input_inv[\"QTL_tool_option\"]}_QTL_recipe.tsv'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/association_scan/$[_input_inv[\"QTL_tool_option\"]]/$[_input_inv[\"QTL_tool_option\"]].ipynb $[_input_inv[\"QTL_tool_option\"]]_$[_input_inv[\"QTL_analysis_option\"]] \\\n",
    "        --molecular_pheno_list $[_input[2]] \\\n",
    "        --covariate $[_input[0]]\\\n",
    "        --genotype_file_list $[_input[3]] \\\n",
    "        --container $[container_apex if _input_inv[\"QTL_tool_option\"] == \"APEX\" else container_TensorQTL] \\\n",
    "        --window $[_input_inv[\"cis_windows\"]] \\\n",
    "        --name $[_input_inv[\"Theme\"]]  \\\n",
    "        --wd $[wd:a]/association_scan/$[_input_inv[\"QTL_tool_option\"]]/$[_input_inv[\"QTL_analysis_option\"]]/ \\\n",
    "        -J 200 -q csg -c $[yml]  $[f'--grm_list {_input[1]}' if _input_inv[\"QTL_tool_option\"] == \"APEX\" else f''] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-spencer",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Example:\n",
    "\n",
    "sos run /home/hs3163/GIT/ADSPFG-xQTL/workflow/QTL_association/QTL_association.ipynb APEX_cis_Recipe \\\n",
    "    --recipe data_preprocessing/PCC.data_proc_output_recipe.tsv \\\n",
    "    --container /mnt/mfs/statgen/containers/apex.sif \\\n",
    "    --window 500000 \\\n",
    "    --name PCC  \\\n",
    "    --wd /mnt/mfs/statgen/xqtl_workflow_testing/testing_no_cov/QTL_association/ \\\n",
    "    -J 200 -q csg -c /home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-declaration",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[QTL_2]\n",
    "input: group_by = \"all\"  \n",
    "output: f'{_input[0]:d}/sumstat_list'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import pandas as pd\n",
    "    input_list = [$[_input:r,]]\n",
    "    input_inv = $[input_inv]\n",
    "    sumstat_list = pd.read_csv(input_list[0],sep = \"\\t\")\n",
    "    sumstat_list = sumstat_list.sort_values('#chr')\n",
    "    for x in range(1,len(input_list)):\n",
    "        sumstat_list = sumstat_list.merge(pd.read_csv(input_list[x],sep = \"\\t\"), on = \"#chr\")\n",
    "\n",
    "    sumstat_list.columns = [\"#chr\"] + pd.DataFrame(input_inv)[\"Theme\"].values.tolist()\n",
    "    sumstat_list.to_csv(\"$[_output]\", index = 0 , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-aerospace",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baking-geology",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Meta Analysis\n",
    "Input: \n",
    "1. A recipe generated from the combination of previouse steps\n",
    "\n",
    "Output: \n",
    "1. Recipe for Prior, Vhat, rds input, resid corr\n",
    "3. vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-puzzle",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[METAL]\n",
    "input: output_from(\"QTL_2\")\n",
    "METAL_sumstat_list = f'{_input}.METAL.tsv'\n",
    "sumstat_list = pd.read_csv(_input,sep = \"\\t\")[[\"#chr\"] + Metal_theme].to_csv(METAL_sumstat_list,sep = \"\\t\", index = 0)\n",
    "output: f'{wd}/multivariate/METAL/{Metal_theme_str}.METAL_list.txt'\n",
    "##task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "        sos run $[exe_dir]/multivariate/METAL/METAL.ipynb METAL \\\n",
    "            --sumstat_list_path $[METAL_sumstat_list]  \\\n",
    "            --wd $[wd:a]/multivariate/METAL/  --container $[container_METAL] \\\n",
    "            -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f884958-e90e-4022-b64f-8e33af8cb693",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## MASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567167ac-1e8d-413a-9fe9-050d21795452",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sumstat_merger_1]\n",
    "parameter: sumstat_list = f'{wd}/multivariate/METAL/{Metal_theme_str}.METAL_list.txt'\n",
    "input: output_from(\"QTL_2\")\n",
    "output: yml_list = f'{wd}/multivariate/MASH/Prep/yml_list.txt',\n",
    "        qced_sumstat_list = f'{wd}/multivariate/MASH/Prep/qc_sumstat_list.txt'\n",
    "##task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "        sos run $[exe_dir]/misc/yml_generator.ipynb yml_list \\\n",
    "            --sumstat_list_path $[_input]  \\\n",
    "            --wd $[wd:a]/multivariate/MASH/Prep/  --container $[container_base_bioinfo]\n",
    "\n",
    "        sos run $[exe_dir]/misc/summary_stats_merger.ipynb  \\\n",
    "            --yml_list $[_output[0]]  \\\n",
    "            --cwd $[wd:a]/multivariate/MASH/Prep/  --container $[container_base_bioinfo]  --keep_ambiguous True \\\n",
    "            -J 200 -q csg -c $[yml] \n",
    "[sumstat_merger_2]\n",
    "input: named_output(\"qced_sumstat_list\")\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "output: f'{wd}/multivariate/MASH/Prep/merge/RDS/{name}.analysis_unit'\n",
    "##task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/multivariate/MASH/sumstat_processing.ipynb processing \\\n",
    "            --sumstat_list_path $[_input] \\\n",
    "            --region_list $[input_inv[0][\"region_list\"]] \\\n",
    "            --wd  $[wd:a]/multivariate/MASH/Prep/  --container  $[container_base_bioinfo]  \\\n",
    "            -J 2000 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba994440-a63f-4e7e-b694-438b20ebdeea",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[extract_effect]\n",
    "input: output_from(\"sumstat_merger\")\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "output: f'{wd}/multivariate/MASH/Prep/{name}.rds'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/multivariate/MASH/Signal_Extraction.ipynb extract_effects \\\n",
    "            --cwd $[wd:a]/multivariate/MASH/Prep/ \\\n",
    "            --container $[container_base_bioinfo] \\\n",
    "            --name  $[name] \\\n",
    "            --analysis_units $[_input]  \\\n",
    "            -J 2000 -q csg -c $[yml]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e80ae3-4ed6-4828-ae22-fbe1b35cf184",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mash_model]\n",
    "input: output_from(\"extract_effect\")\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "output: MASH_model = f\"{wd}/multivariate/MASH/{name}.EZ.V_simple.mash_model.rds\",\n",
    "        resid_corr = f\"{wd}/multivariate/MASH/{name}.EZ.V_simple.rds\"\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "        sos run $[exe_dir]/multivariate/MASH/mashr.ipynb mash \\\n",
    "            --cwd $[wd:a]/multivariate/MASH/ \\\n",
    "            --container $[container_mvsusie] \\\n",
    "            --output_prefix  $[name] \\\n",
    "            --data $[_input]  \\\n",
    "            -J 200 -q csg -c $[yml] \n",
    "\n",
    "[mash_posterior]\n",
    "input: output_from(\"mash_model\")[\"MASH_model\"], output_from(\"sumstat_merger\")\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "parameter: analysis_unit = _input[1]\n",
    "output: f'{wd}/multivariate/MASH/mash_output_list'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/multivariate/MASH/mashr.ipynb posterior \\\n",
    "            --cwd $[wd:a]/multivariate/MASH/ \\\n",
    "            --container $[container_mvsusie] \\\n",
    "            --output_prefix  $[name] \\\n",
    "            --analysis_units $[analysis_unit]  \\\n",
    "            -J 2000 -q csg -c $[yml] \n",
    "\n",
    "[mash_to_vcf]\n",
    "input: output_from(\"mash_posterior\")\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "output: f'{wd}/multivariate/MASH/mash_vcf/vcf_output_list.txt'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/misc/rds_to_vcf.ipynb rds_to_vcf \\\n",
    "            --wd $[wd:a]/multivariate/MASH/ \\\n",
    "            --name  $[name] \\\n",
    "            --analysis_units $[_input]  \\\n",
    "            -J 2000 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a82997-6881-48dd-ac14-7a3f4b3c48f6",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2410b-9cc3-4c49-8f2e-da2c833f1fc0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffdc066a-f824-4051-ac1e-d538225339ac",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Fine mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce171d-7047-4d8e-9865-42261fd02c21",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mixture_prior]\n",
    "input: output_from(\"mash_model\")[\"MASH_model\"], output_from(\"extract_effect\")\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "output: f'{wd}/fine_mapping/mixture_prior/{name}.ed_bovy.V_simple.rds'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/multivariate/MASH/mixture_prior.ipynb ed_bovy \\\n",
    "            --cwd $[wd:a]/fine_mapping/mixture_prior/ \\\n",
    "            --container $[container_mvsusie] \\\n",
    "            --name  $[name] \\\n",
    "            --data $[_input[1]]  \\\n",
    "            --mixture_components_dir $[_input[0]:d]  \\\n",
    "            -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a267ad-0571-4692-8f87-792ee4301326",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/multivariate/MASH/mixture_prior.ipynb ed_bovy --model_data fine_mapping/mixture_prior/AC_DLPFC_PCC.ed_bovy.V_simple.rds   --cwd ./    --container /mnt/mfs/statgen/containers/twas_latest.sif     --name  AC_DLPFC_PCC     --data multivariate/MASH/Prep/AC_DLPFC_PCC.rds     --mixture_components_dir multivariate/MASH      -J 200 -q csg -c /home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd4739-2418-4b7d-930b-62e267e2db7a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mvsusie_rss]\n",
    "input: output_from(\"mixture_prior\"), output_from(\"sumstat_merger\"), output_from(\"mash_model\")[\"resid_corr\"]\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "parameter: analysis_unit = _input[1]\n",
    "output: f'{wd:a}/fine_mapping/mvsusie_rss/{name}.mvsusie_rss.output_list.txt'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/fine_mapping/SuSiE/SuSiE_RSS.ipynb MvSuSiE_summary_stats_analysis \\\n",
    "            --merged_analysis_unit $[analysis_unit] \\\n",
    "            --resid_cor $[_input[2]] \\\n",
    "            --prior $[_input[0]] \\\n",
    "            --LD_Recipe /home/hs3163/GIT/ADSPFG-xQTL/MWE/LD_Recipe \\\n",
    "            --container $[container_mvsusie] \\\n",
    "            --wd   $[wd:a]/fine_mapping/mvsusie_rss/ \\\n",
    "            --Theme_prefix $[name]             -J 200 -q csg -c $[yml] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4e39d-d3e8-47a5-a479-69ff611c5999",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/fine_mapping/SuSiE/SuSiE_RSS.ipynb MvSuSiE_summary_stats_analysis \\\n",
    "    --merged_analysis_unit /mnt/mfs/statgen/xqtl_workflow_testing/ROSMAP/showcase_gene \\\n",
    "    --resid_cor multivariate/MASH/AC_DLPFC_PCC.EZ.V_simple.rds \\\n",
    "    --prior /mnt/mfs/statgen/xqtl_workflow_testing/ROSMAP/fine_mapping/mixture_prior/AC_DLPFC_PCC.ed_bovy.V_simple.rds \\\n",
    "    --LD_Recipe /home/hs3163/GIT/ADSPFG-xQTL/MWE/LD_Recipe \\\n",
    "    --container /mnt/mfs/statgen/containers/twas_latest.sif \\\n",
    "    --wd   /mnt/mfs/statgen/xqtl_workflow_testing/ROSMAP/fine_mapping/mvsusie_rss/ \\\n",
    "    --Theme_prefix AC_DLPFC_PCC              -J 200 -q csg -c  /home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml -s build  &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654eff25-617d-4e98-ac2f-eed451696cc8",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[unisusie_rss]\n",
    "input: output_from(\"mixture_prior\"), output_from(\"sumstat_merger\"), output_from(\"mash_model\")[\"resid_corr\"]\n",
    "name = \"_\".join(pd.DataFrame(input_inv)[\"Theme\"].values.tolist())\n",
    "parameter: analysis_unit = _input[1]\n",
    "output: f'{wd:a}/fine_mapping/unisusie_rss/{name}.unisusie_rss.output_list.txt'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/fine_mapping/SuSiE/SuSiE_RSS.ipynb UniSuSiE_summary_stats_analysis \\\n",
    "            --merged_analysis_unit $[analysis_unit] \\\n",
    "            --LD_Recipe /home/hs3163/GIT/ADSPFG-xQTL/MWE/LD_Recipe \\\n",
    "            --container $[container_mvsusie] \\\n",
    "            --wd   $[wd:a]/fine_mapping/unisusie_rss/ \\\n",
    "            --Theme_prefix $[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d7ef1-d5d7-4fd0-96e3-fc5dcc44349a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/multivariate/MASH/mashr.ipynb mash \\\n",
    "    --cwd ./ \\\n",
    "    --container /mnt/mfs/statgen/containers/xqtl_pipeline_sif/mvsusie.sif \\\n",
    "    --output_prefix  AC_DLPFC_PCC \\\n",
    "    --data /mnt/mfs/statgen/xqtl_workflow_testing/ROSMAP/multivariate/MASH/Prep/AC_DLPFC_PCC.rds  \\\n",
    "    -J 200 -q csg -c /home/hs3163/GIT/ADSPFG-xQTL/code/csg.yml &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-planet",
   "metadata": {
    "kernel": "SoS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-lying",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[unisusie]\n",
    "input: output_from(\"phenotype_reformatting_per_gene\"),output_from(\"genotype_reformatting_per_gene\"), group_with = \"input_inv\"\n",
    "output: f'{wd:a}/fine_mapping/unisusie/{name}/{name}.unisusie.output_list.txt'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/fine_mapping/SuSiE/SuSiE.ipynb UniSuSiE_summary_stats_analysis uni_susie \\\n",
    "        --phenotype_list $[_input[0]] \\\n",
    "        --genotype_list $[_input[1]] \\\n",
    "        --container $[container_mvsusie] \\\n",
    "        --region_list $[_input_inv[\"region_list\"]] \\\n",
    "        --name $[_input_inv[\"Theme\"]]  \\\n",
    "        --wd $[wd:a]/fine_mapping/unisusie/$[name]/ \\\n",
    "        -J 200 -q csg -c $[yml] &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Markdown",
     "markdown",
     "markdown",
     "",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
