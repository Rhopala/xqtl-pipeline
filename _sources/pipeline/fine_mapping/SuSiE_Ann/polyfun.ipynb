{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfd1f61-720f-4814-a763-3c483b1bfa90",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Fine-mapping with PolyFun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17181047-82d9-408b-b8e5-99816341784f",
   "metadata": {
    "kernel": "Markdown",
    "tags": []
   },
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf46667-1481-4ccd-8db4-0e682d9e854a",
   "metadata": {
    "kernel": "Markdown",
    "tags": []
   },
   "source": [
    "The purpose of this notebook is to demonstrate a functionally-informed fine-mapping workflow using the PolyFun method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b5b59-0d48-49e9-90b4-670371f4a88d",
   "metadata": {
    "kernel": "Markdown"
   },
   "source": [
    "## Methods Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b2ed3-6751-4406-a23f-4e35cb3f7404",
   "metadata": {
    "kernel": "Markdown"
   },
   "source": [
    "## Input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f692d-ed06-473c-ba07-9920165ad88c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1) GWAS summary statistics including the following variables: \n",
    "\n",
    "- variant_id - variant ID \n",
    "- P - p-value \n",
    "- CHR - chromosome number \n",
    "- BP - base pair position\n",
    "- A1 - The effect allele (i.e., the sign of the effect size is with respect to A1)\n",
    "- A2 - the second allele \n",
    "- MAF - minor allele frequency \n",
    "- BETA - effect size \n",
    "- SE - effect size standard error\n",
    "\n",
    "2) SNP-identifier file or S-LDSC (stratified LD-score regression) LD-score and annotation file\n",
    "\n",
    "   SNP-identifier file should include the following columns: \n",
    "\n",
    "- CHR - chromosome\n",
    "- BP - base pair position (in hg19 coordinates)\n",
    "- A1 - The effect allele \n",
    "- A2 - the second allele\n",
    "\n",
    "3) Ld-score weights file \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df89b45-0910-4989-bc1d-fdb20dc95fce",
   "metadata": {
    "kernel": "Markdown"
   },
   "source": [
    "## Output\n",
    "\n",
    "A `.gz` file containing input summary statistics columns and additionally the following columns:\n",
    "\n",
    "- PIP - posterior causal probability\n",
    "- BETA_MEAN - posterior mean of causal effect size (in standardized genotype scale)\n",
    "- BETA_SD - posterior standard deviation of causal effect size (in standardized genotype scale)\n",
    "- CREDIBLE_SET - the index of the first (typically smallest) credible set that the SNP belongs to (0 means none).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c32642-3bb1-49a0-adfa-a12dbe957c4c",
   "metadata": {
    "kernel": "Markdown"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc256a-bda9-45a0-9aae-9371f06ab2c5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: Compute Prior Causal Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ffc404-4d6e-44f9-8b4b-aa6f073eaab0",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Method 1: Use precomputed prior causal probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3b503-9144-40b2-8587-cf1e9caa52bb",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Use precomputed prior causal probabilities of 19 million imputed UK Biobank SNPs with MAF>0.1%, based on a meta-analysis of 15 UK Biobank traits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d69ec9-a725-4342-b5c4-1458105de3f1",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[prior_causal_prob]\n",
    "parameter: sumstats = \n",
    "bash: container='/mnt/mfs/statgen/tl3030/SIF/polyfun_ninth.sif'\n",
    "    mkdir -p /mnt/mfs/statgen/tl3030/AD_output\n",
    "    python /mnt/mfs/statgen/tl3030/extract_snpvar.py \\\n",
    "        --sumstats AD_sumstats_Jansenetal_2019sept.txt.gz \\\n",
    "        --out /mnt/mfs/statgen/tl3030/AD_output/AD_snps_with_var.gz \\\n",
    "        --allow-missing\n",
    "    cat /mnt/mfs/statgen/tl3030/AD_output/AD_snps_with_var.gz | zcat | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dfabc6-a216-4de7-a8da-95ef574baead",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Method 2: Compute via L2-regularized extension of S-LDSC (preferred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d6c08a-9b4b-4309-a5da-6adbeca7d762",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Compute via an L2-regularized extension of stratified LD-score regression (S-LDSC). Procedure for both methods is shown in this workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97245757-1817-4236-ab8f-fc86ac047e2d",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[munged_sumstats]\n",
    "parameter: sumstats = \n",
    "bash: container='/mnt/mfs/statgen/tl3030/SIF/polyfun_ninth.sif'\n",
    "    mkdir -p /mnt/mfs/statgen/tl3030/AD_SLDSC_output\n",
    "    python /mnt/mfs/statgen/tl3030/munge_polyfun_sumstats.py \\\n",
    "      --sumstats AD_sumstats_Jansenetal_2019sept.txt.gz \\\n",
    "      --n 450734 \\\n",
    "      --out /mnt/mfs/statgen/tl3030/AD_SLDSC_output/sumstats_munged.parquet \\\n",
    "      --min-info 0 \\\n",
    "      --min-maf 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f6bf2-410a-4c5b-8951-7a7340a5b329",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Create functional annotations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec89f80-7eb9-4618-81ef-16ef73fa445d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Method 1: Use existing function annotation files \n",
    "\n",
    "Use functional annotations for ~19 million UK Biobank imputed SNPs with MAF>0.1%, based on the baseline-LF 2.2.UKB annotations\n",
    "\n",
    "Download (30G): https://data.broadinstitute.org/alkesgroup/LDSCORE/baselineLF_v2.2.UKB.polyfun.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62380ee-324b-4bb2-83b9-c4856eab2364",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Method 2: Create annotations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34f515-28ad-4ffd-9416-bf5a98c5ab4c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To create your own annotations, for each chromosome, the following files are needed: \n",
    "\n",
    "1) A `.gz` or `.parquet` Annotations file containing the following columns:\n",
    "\n",
    "- CHR - chromosome number\n",
    "- BP base pair position\n",
    "- SNP - dbSNP reference number \n",
    "- A1 - The effect allele \n",
    "- A2 - the second allele\n",
    "- Arbitrary additional columns representing annotations \n",
    "\n",
    "2) A `.l2.M` white-space delimited file containing a single line with the sums of the columns of each annotation\n",
    "\n",
    "3) (Optional) A `l2.M_5_50` file that is the `.l2.M` but only containing common SNPS (MAF between 5% and 50%) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad4e2b-8e56-4ffb-8f07-5adf4e517073",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: Compute LD-scores for annotations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba02ea-7614-4725-968a-fa291ca6c21c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Method 1: Compute with reference panel of sequenced individuals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ac711-c423-45a6-8540-de42a5620b21",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Reference panel should have at least 3000 sequenced individuals from target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e599c4-6520-4a88-9863-613898060535",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ld_score]\n",
    "bash: container = ''\n",
    "    mkdir -p\n",
    "    python compute_ldscores.py \\\n",
    "    --bfile example_data/reference.1 \\\n",
    "    --annot example_data/annotations.1.annot.parquet \\\n",
    "    --out output/ldscores_example.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871bf7bc-dd52-42a1-8676-e3778ac56a58",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Method 2: Compute with pre-computed UK Biobank LD matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250da1f9-d8bf-4103-86b8-d78da97e27a8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Matrices download: https://data.broadinstitute.org/alkesgroup/UKBB_LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb0444-f80a-45f8-8a04-9926faf2ffd8",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ld_score_uk]\n",
    "base: container = ''\n",
    "    mkdir -p \n",
    "    python compute_ldscores_from_ld.py \\\n",
    "    --annot example_data/annotations.1.annot.parquet \\\n",
    "    --ukb \\\n",
    "    --out output/ldscores_example2.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4cef6-6283-4acd-bba0-dcbb7c19a4c7",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Method 3: Compute with own pre-computed LD matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9e6d7-fbc2-4ff1-a52a-bdd01889a4e6",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Own pre-computed LD matrices should be in `.bcor` format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d88f2-50c5-46f4-9942-293f71a1c7a0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ld_score_own]\n",
    "base: container = ''\n",
    "    mkdir -p \n",
    "    python compute_ldscores_from_ld.py \\\n",
    "    --annot example_data/annotations.1.annot.parquet \\\n",
    "    --out output/ldscores_example3.parquet \\\n",
    "    --n 10000 \\\n",
    "    bcor_files/*.bcor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e9355-2ce3-4760-9a98-e1223f28146a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 4: Run PolyFun with L2-regularized S-LDSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90c692-8af7-4775-9b31-91f739e83432",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "If prior causal probabilities aren't computed,then use `finemapper.py` instead of `polyfun.py` to perform non-functionally-informed fine-mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1b9bc-6b06-40c5-8c3c-1996881c56df",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[L2_regu_SLDSC]\n",
    "bash: container='/mnt/mfs/statgen/tl3030/SIF/polyfun_ninth.sif'\n",
    "    python /mnt/mfs/statgen/tl3030/polyfun.py \\\n",
    "    --compute-h2-L2 \\\n",
    "    --no-partitions \\\n",
    "    --output-prefix /mnt/mfs/statgen/tl3030/AD_SLDSC_output/testrun \\\n",
    "    --sumstats /mnt/mfs/statgen/tl3030/AD_SLDSC_output/sumstats_munged.parquet \\\n",
    "    --ref-ld-chr /mnt/mfs/statgen/tl3030/baselineLF2.2.UKB/baselineLF2.2.UKB. \\\n",
    "    --w-ld-chr /mnt/mfs/statgen/tl3030/weights.UKB.l2.ldscore/weights.UKB. \\\n",
    "    --allow-missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3e734-ee0a-409c-8754-46987fbeb407",
   "metadata": {
    "kernel": "Markdown"
   },
   "source": [
    "## Minimal Working Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e2779-3117-4805-a549-c7bcc63446b1",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "module load Singularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f2e1c-6a24-4e31-81b8-464a18d674ca",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat /mnt/mfs/statgen/tl3030/GCST90012877_buildGRCh37.tsv.gz | zcat | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379579c5-80ad-497a-8d3a-077cf8601090",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[modification]\n",
    "\n",
    "python: expand = \"${ }\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    # Read in data\n",
    "    sumstat = pd.read_csv('/mnt/mfs/statgen/tl3030/GCST90012877_buildGRCh37.tsv', sep='\\t', header=0)\n",
    "\n",
    "    # Rename columns so that munge_polyfun_sumstats.py could recognize it\n",
    "    sumstat.rename(columns={'SNP_ID': 'SNP', 'chromosome': 'CHR', 'base_pair_location': 'BP', \n",
    "                        'effect_allele': 'A1', 'other_allele': 'A2', 'effect_allele_frequency': 'MAF', \n",
    "                        'p_value': 'P', 'standard_error': 'SE'}, inplace=True, errors='raise')\n",
    "\n",
    "    # Replace NaN with string `chr_bp_ref_alt`\n",
    "    cols = ['CHR', 'BP', 'A2', 'A1']\n",
    "\n",
    "    sumstat['variant_id'] = sumstat['variant_id'].fillna('refill')\n",
    "\n",
    "    for k,row in sumstat.iterrows():\n",
    "        if row['variant_id'] == 'refill':\n",
    "            replace = '_'.join(row[cols].values.astype(str))\n",
    "            print(k)\n",
    "            sumstat.loc[k, 'variant_id']=replace \n",
    "\n",
    "    # Write out data in a .txt file\n",
    "    sumstat.to_csv('/mnt/mfs/statgen/tl3030/GCST90012877_buildGRCh37_colrenamed.txt', index=False, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e23a8a-c0b5-4405-9cfa-ed5882c81702",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[munged_sumstats]\n",
    "bash: container='/mnt/mfs/statgen/tl3030/SIF/polyfun_ninth.sif'\n",
    "    mkdir -p /mnt/mfs/statgen/tl3030/AD_2021_output\n",
    "    python /mnt/mfs/statgen/tl3030/munge_polyfun_sumstats.py \\\n",
    "      --sumstats /mnt/mfs/statgen/tl3030/GCST90012877_buildGRCh37_colrenamed.txt.gz \\\n",
    "      --n 472868 \\\n",
    "      --out /mnt/mfs/statgen/tl3030/AD_2021_output/sumstats_munged.parquet \\\n",
    "      --min-info 0.6 \\\n",
    "      --min-maf 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08023de6-304f-4f3a-90f2-0eea2e6969ba",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run /mnt/mfs/statgen/tl3030/Untitled1.ipynb munged_sumstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ce608-a77a-4898-8100-1c0c5c84673b",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "munged_file = pd.read_parquet('/mnt/mfs/statgen/tl3030/AD_2021_output/sumstats_munged.parquet', engine='auto')\n",
    "print(munged_file.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735957e8-5780-4c95-ac43-55ed8a6905aa",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[L2_regu_SLDSC]\n",
    "bash: container='/mnt/mfs/statgen/tl3030/SIF/polyfun_ninth.sif'\n",
    "    python /mnt/mfs/statgen/tl3030/polyfun.py \\\n",
    "    --compute-h2-L2 \\\n",
    "    --no-partitions \\\n",
    "    --output-prefix /mnt/mfs/statgen/tl3030/AD_2021_output/testrun \\\n",
    "    --sumstats /mnt/mfs/statgen/tl3030/AD_2021_output/sumstats_munged.parquet \\\n",
    "    --ref-ld-chr /mnt/mfs/statgen/tl3030/baselineLF2.2.UKB/baselineLF2.2.UKB. \\\n",
    "    --w-ld-chr /mnt/mfs/statgen/tl3030/weights.UKB.l2.ldscore/weights.UKB. \\\n",
    "    --allow-missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9ad7b-8f72-4310-8538-3df2f149d681",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run /mnt/mfs/statgen/tl3030/Untitled1.ipynb L2_regu_SLDSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f0ca7-d98d-4cd9-bcf8-e45358b814c0",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a07162-b253-430e-a70f-e4110dd7a0cd",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "# get the location of finemapping result files\n",
    "file_with_annot_location = os.path.join('/mnt', 'mfs', 'statgen','tl3030','AD_2021_output','with_annot', 'finemap.*.gz')\n",
    "print(file_with_annot_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f91f7f-f923-47ec-900a-31b4eb03f227",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# get a list of result file name\n",
    "filenames_with_annot = glob.glob(file_with_annot_location)\n",
    "print(len(filenames_with_annot))\n",
    "print(filenames_with_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228de308-67a6-49b3-ae22-f21fd146e2bc",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "snp_with_annot = pd.DataFrame()\n",
    "\n",
    "for f in filenames_with_annot:\n",
    "    # read the data\n",
    "    outfile = pd.read_csv(f, delimiter = \"\\t\")\n",
    "    \n",
    "    # filter out SNPs that has PIP >= 0.95\n",
    "    significant = (outfile[outfile['PIP']>=0.95])\n",
    "    snp_with_annot = snp_with_annot.append(significant)\n",
    "\n",
    "print(snp_with_annot.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585872ce-01ed-49be-a782-2ff0193b5472",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to check duplicate\n",
    "def checkIfDuplicates(snp):\n",
    "    ''' Check if given list contains any duplicates '''\n",
    "    if len(snp) == len(set(snp)):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# check if there is duplicates\n",
    "result = checkIfDuplicates(snp)\n",
    "if result:\n",
    "    print('Yes, list contains duplicates')\n",
    "else:\n",
    "    print('No duplicates found in list') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75374903-ba87-4135-85b8-1a4ce64f48fc",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove duplicated SNPs\n",
    "snp_with_annot_uniq = snp_with_annot.drop_duplicates(subset='SNP', keep='first')\n",
    "print(snp_with_annot_uniq.head(5))\n",
    "print(snp_with_annot_uniq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb322e-c2c7-438f-83a9-54ed73edb293",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CS_with_annot = pd.DataFrame()\n",
    "\n",
    "for f in filenames_with_annot:\n",
    "    # read the data\n",
    "    outfile = pd.read_csv(f, delimiter = \"\\t\")\n",
    "    \n",
    "    # filter out SNPs that has CS\n",
    "    significant = (outfile[outfile['CREDIBLE_SET']>0])\n",
    "    CS_with_annot = CS_with_annot.append(significant)\n",
    "\n",
    "print(CS_with_annot.head(5))\n",
    "print(CS_with_annot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d168e-b807-4658-a4eb-dba8b8fb129f",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove duplicated SNPs\n",
    "CS_with_annot_uniq = CS_with_annot.drop_duplicates(subset='SNP', keep='first')\n",
    "print(CS_with_annot_uniq.head(5))\n",
    "print(CS_with_annot_uniq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b83b7-041b-4026-be45-2f8d780c1bee",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d62e5-053b-40c9-8863-d8b361497429",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the range file\n",
    "region_range = pd.read_csv(\"/mnt/mfs/statgen/tl3030/range.csv\").dropna()\n",
    "#chr1_160990767_161203192 = pd.read_csv(\"/mnt/mfs/statgen/tl3030/finemapping_result_97gene/finemap.1.160990767.161203192.gz\", delimiter = \"\\t\")\n",
    "#print(chr1_160990767_161203192.head())\n",
    "\n",
    "bpcol = CS_with_annot_uniq[['CHR', 'BP']]\n",
    "#print(bpcol.head())\n",
    "\n",
    "# Assign SNPs to the gene region that it belong to\n",
    "j = 0\n",
    "for i, bp in bpcol.iterrows():\n",
    "    #print(i, bp['CHR'])\n",
    "    for k,row in region_range.iterrows():\n",
    "        if (bp['CHR'] == row['Chr']) and (bp['BP'] > row['start']) and (bp['BP'] < row['end']):\n",
    "            #print(row['Chr'],row['Gene Name'])\n",
    "            #print(i, bp['CHR'], row['Chr'], row['Gene Name'])\n",
    "            CS_with_annot_uniq.iloc[j,15] = row['Gene Name']\n",
    "            #pass\n",
    "            #CS_with_annot_uniq.loc[j,'GENE']= row['Gene Name']\n",
    "    j += 1\n",
    "\n",
    "print(CS_with_annot_uniq.head(5))\n",
    "print(CS_with_annot_uniq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd898b62-7f74-4dea-aedc-737ebcf9d7ef",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "CS_with_annot_uniq.to_csv('/mnt/mfs/statgen/tl3030/AD_2021_output/variants_with_CS_2021sumstat_97genes_with_annot.txt', index=False, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70f27e-8119-45d3-89ec-1f321030c9f9",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CS_with_annot_uniq.sort_values(by=['CHR']) # sort the file by chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957eac7-83a7-4250-8bdb-52580996dbd6",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_of_CS_with_annot = CS_with_annot_uniq.drop_duplicates(subset=['CREDIBLE_SET', 'GENE'], keep = 'last').reset_index(drop = True)\n",
    "print(num_of_CS_with_annot.shape)\n",
    "num_of_CS_with_annot.sort_values(by=['GENE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4d778-3e5d-44e3-987f-252c863962ea",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "num_of_gene_with_annot = CS_with_annot_uniq.drop_duplicates(subset=['GENE'], keep = 'last').reset_index(drop = True)\n",
    "print(num_of_gene_with_annot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de077b-0a9a-4411-9d59-89f7fa0e0619",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_frequency_with_annot = CS_with_annot_uniq.groupby([\"CREDIBLE_SET\", \"GENE\"]).size().reset_index(name=\"Time\")\n",
    "print(check_frequency_with_annot.head(5))\n",
    "print(check_frequency_with_annot.shape)\n",
    "\n",
    "print(check_frequency_with_annot['Time'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ddeff-37d8-4d46-82bb-8073dcecef9d",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CS_with_1_variant_with_annot = check_frequency_with_annot[check_frequency_with_annot['Time'] == 1]\n",
    "print(CS_with_1_variant_with_annot.shape)\n",
    "print(CS_with_1_variant_with_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571486a2-64dc-40ec-ac3d-1c3187d2273f",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_with_annot = CS_with_annot_uniq['GENE']\n",
    "print(gene_with_annot.shape)\n",
    "\n",
    "gene_list_with_annot = gene_with_annot.drop_duplicates()\n",
    "print(gene_list_with_annot)\n",
    "print(gene_list_with_annot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd62e3-636b-40cf-b7e7-e771008771dd",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "###  Summary of Fine-mapping Result Without Functional Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25d7bc-cee2-45a4-9112-7cb0f021aee0",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "# get the location of finemapping result files\n",
    "file_without_annot_location = os.path.join('/mnt', 'mfs', 'statgen','tl3030','AD_2021_output','without_annot', 'finemap.*.gz')\n",
    "print(file_without_annot_location)\n",
    "\n",
    "import glob\n",
    "# get a list of result file name\n",
    "filenames_without_annot = glob.glob(file_without_annot_location)\n",
    "print(len(filenames_without_annot))\n",
    "print(filenames_without_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d883d-a444-4f3a-af1a-095406fa8dc9",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "snp_without_annot = pd.DataFrame()\n",
    "\n",
    "for f in filenames_without_annot:\n",
    "    # read the data\n",
    "    outfile = pd.read_csv(f, delimiter = \"\\t\")\n",
    "    \n",
    "    # filter out SNPs that has PIP >= 0.95\n",
    "    significant = (outfile[outfile['PIP']>=0.95])\n",
    "    snp_without_annot = snp_without_annot.append(significant)\n",
    "\n",
    "print(snp_without_annot.head(5))\n",
    "\n",
    "# remove duplicated SNPs\n",
    "snp_without_annot_uniq = snp_without_annot.drop_duplicates(subset='SNP', keep='first')\n",
    "print(snp_without_annot_uniq.head(5))\n",
    "print(snp_without_annot_uniq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45442005-d954-45a5-a242-49174e6f59f3",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CS_without_annot = pd.DataFrame()\n",
    "\n",
    "for f in filenames_without_annot:\n",
    "    # read the data\n",
    "    outfile = pd.read_csv(f, delimiter = \"\\t\")\n",
    "    \n",
    "    # filter out SNPs that has CS\n",
    "    significant = (outfile[outfile['CREDIBLE_SET']>0])\n",
    "    CS_without_annot = CS_without_annot.append(significant)\n",
    "\n",
    "# remove duplicated SNPs\n",
    "CS_without_annot_uniq = CS_without_annot.drop_duplicates(subset='SNP', keep='first')\n",
    "print(CS_without_annot_uniq.head(5))\n",
    "print(CS_without_annot_uniq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3a815-c7a9-4456-a1cb-47a750ae338e",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the range file\n",
    "region_range = pd.read_csv(\"/mnt/mfs/statgen/tl3030/range.csv\").dropna()\n",
    "\n",
    "bpcol = CS_without_annot_uniq[['CHR', 'BP']]\n",
    "\n",
    "# Assign SNPs to the gene region that it belong to\n",
    "j = 0\n",
    "for i, bp in bpcol.iterrows():\n",
    "    #print(i, bp['CHR'])\n",
    "    for k,row in region_range.iterrows():\n",
    "        if (bp['CHR'] == row['Chr']) and (bp['BP'] > row['start']) and (bp['BP'] < row['end']):\n",
    "            CS_without_annot_uniq.iloc[j,15] = row['Gene Name']\n",
    "            #CS_without_annot_uniq.loc[j,'GENE']= row['Gene Name']\n",
    "    j += 1\n",
    "\n",
    "print(CS_without_annot_uniq.head(5))\n",
    "print(CS_without_annot_uniq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d2a38d-d3b6-4a7d-99da-36236106c224",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_of_CS_without_annot = CS_without_annot_uniq.drop_duplicates(subset=['CREDIBLE_SET', 'GENE'], keep = 'last').reset_index(drop = True)\n",
    "print(num_of_CS_without_annot.shape)\n",
    "num_of_CS_without_annot.sort_values(by=['GENE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7082551-d638-438a-bcdd-365c426b7747",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "num_of_gene_without_annot = CS_without_annot_uniq.drop_duplicates(subset=['GENE'], keep = 'last').reset_index(drop = True)\n",
    "print(num_of_gene_without_annot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92396d-3de0-40ec-9215-97aa38790fdf",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_frequency_without_annot = CS_without_annot_uniq.groupby([\"CREDIBLE_SET\", \"GENE\"]).size().reset_index(name=\"Time\")\n",
    "print(check_frequency_without_annot.head(5))\n",
    "print(check_frequency_without_annot.shape)\n",
    "\n",
    "print(check_frequency_without_annot['Time'].sum())\n",
    "\n",
    "CS_with_1_variant_without_annot = check_frequency_without_annot[check_frequency_without_annot['Time'] == 1]\n",
    "print(CS_with_1_variant_without_annot.shape)\n",
    "print(CS_with_1_variant_without_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d11999-90ea-4f6e-a1b0-585ef51cc4e4",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_without_annot = CS_without_annot_uniq['GENE']\n",
    "print(gene_without_annot.shape)\n",
    "\n",
    "gene_list_without_annot = gene_without_annot.drop_duplicates()\n",
    "print(gene_list_without_annot)\n",
    "print(gene_list_without_annot.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Markdown",
     "markdown",
     "markdown",
     "",
     "markdown"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
