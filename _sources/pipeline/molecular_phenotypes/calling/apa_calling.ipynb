{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prompt-thomson",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# APA Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-calibration",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim\n",
    "The purpose of this notebook is to call APA-based information (PDUI) based on DAPARS2 method\n",
    "(https://github.com/3UTR/DaPars2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-teaching",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Methods overview\n",
    "\n",
    "![APA calling pipeline](../../../../_images/apa_calling.png)\n",
    "\n",
    "(Optional) 3UTR Generation:\n",
    "* _gtf2bed12.py_ : Covert gtf to bed format (Source from in-house codes from Li Lab: https://github.com/Xu-Dong/Exon_Intron_Extractor/blob/main/scripts/gtf2bed12.py)  \n",
    "\n",
    "    `wget https://raw.githubusercontent.com/seriousbamboo/Exon_Intron_Extractor/main/scripts/gtf2bed12.py`\n",
    "\n",
    "* _DaPars_Extract_Anno.py_ : extract the 3UTR regions in bed formats from the whole genome bed (Source from Dapars 2: https://github.com/3UTR/DaPars2/blob/master/src/DaPars_Extract_Anno.py)\n",
    "\n",
    "    `wget https://raw.githubusercontent.com/3UTR/DaPars2/master/src/DaPars_Extract_Anno.py`\n",
    "\n",
    "1 - Config files Generation:  \n",
    "* _Python 3_ loops to read line by line the sum of reads coverage of all chromosome.\n",
    "\n",
    "2 - Dapars2 Main Function:\n",
    "* _Dapars2_Multi_Sample.py_: use the least sqaures methods to calculate the usage of long isoforms (https://github.com/3UTR/DaPars2/blob/master/src/Dapars2_Multi_Sample.py)  \n",
    "\n",
    "    `wget https://raw.githubusercontent.com/seriousbamboo/DaPars2/master/src/Dapars2_Multi_Sample.py`\n",
    "    \n",
    "    Note: this part of code have been modified from source to deal with some formatting discrepancy in wig file\n",
    "\n",
    "3 - Impute missing values in Dapars result\n",
    "\n",
    "#### Dependence\n",
    "* _Python2_ (Note: codes in python2 can be update to Python 3 easily)\n",
    "* _Python3_\n",
    "* _R_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-custom",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Input for the whole Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-grill",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Required input: \n",
    "*  The path to the directory where the wig files are stored (denoted as bfile, please refer to further sessions for more detailed requirment)\n",
    "*  The 3'UTR annotation file\n",
    "\n",
    "If you do not have 3'UTR annotation file, please generate it following step 1. The input of generation is:\n",
    "*  GTF(served as the reference) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-leisure",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-geology",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "*  Dapars config files (in the current directory)\n",
    "*  PUDI (Raw) information saved in txt (in the specified output directory)\n",
    "*  PDUI (Imputed) information saved in txt. This can be used for further analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-period",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "congressional-intensity",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: walltime = '36h'\n",
    "parameter: mem = '100G'\n",
    "parameter: ncore = 22\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# path to GTF file \n",
    "parameter: thread = 8\n",
    "parameter: job_size = 22\n",
    "parameter: container = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-melissa",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 0: Generate 3UTR regions based on GTF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-display",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The 3UTR regions (saved in bed format) could be use __repeatly__ for different samples. It only served as the reference region, such that you __should not__ run it if given generated hg19/hg38 3UTR regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attached-blink",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Generate the 3UTR region according to the gtf file\n",
    "[UTR_generation_1]\n",
    "# gtf file\n",
    "parameter: gtf = path\n",
    "input: gtf\n",
    "output: [f'{cwd}/gene_annotation.bed', f'{cwd}/transcript_to_geneName.txt']\n",
    "bash: expand = '${ }', container = container\n",
    "    python2 ../../../code/gtf2bed12.py --gtf \"${_input}\" --out \"${cwd}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "after-springfield",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[UTR_generation_2]\n",
    "parameter: gtf = path\n",
    "input: [f'{cwd}/gene_annotation.bed', f'{cwd}/transcript_to_geneName.txt']\n",
    "output: f'{cwd}/{gtf:bn}_3UTR.bed'\n",
    "bash: expand = '${ }', container = container\n",
    "    python2 ../../../code/DaPars_Extract_Anno.py -b \"${_input[0]}\" -s \"${_input[1]}\" -o \"${_output}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-password",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Step 1: Generating config files and calculating sample depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-hungary",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Notes on input file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-recognition",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "For the input file, it has the following format. Additional notes are:\n",
    "* The first line is the information of file. If you do not have them, please add any content on first line\n",
    "* The file must end with \".wig\". It will not cause any problem if you directly change from \".bedgraph\"\n",
    "* If your input wig file did not have the characters __\"chr\"__ in the first column, please set `no_chr_prefix = T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "american-employer",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track type=bedGraph\n",
      "1\t0\t10099\t0\n",
      "1\t10099\t10113\t1\n",
      "1\t10113\t10146\t0\n",
      "1\t10146\t10157\t2\n",
      "1\t10157\t10230\t0\n",
      "1\t10230\t10241\t2\n",
      "1\t10241\t10279\t0\n",
      "1\t10279\t10301\t1\n",
      "1\t10301\t10329\t0\n"
     ]
    }
   ],
   "source": [
    "head -n 10 /mnt/mfs/statgen/ls3751/MWE_dapars2/sample1.wig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "honest-brush",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculcate total depth and configuration file\n",
    "[APAconfig]\n",
    "parameter: bfile = path\n",
    "parameter: annotation = path\n",
    "parameter: job_size = 1\n",
    "# Default parameters for Dapars2:\n",
    "parameter: least_pass_coverage_percentage = 0.3\n",
    "parameter: coverage_threshold = 10\n",
    "parameter: no_chr_prefix = \"F\"\n",
    "output: [f'{cwd}/sample_mapping_files.txt',f'{cwd}/sample_configuration_file.txt']\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = walltime, mem = mem, cores = ncore\n",
    "python3: expand = \"${ }\", container = container\n",
    "    import re\n",
    "    import os\n",
    "    target_all_sample = os.listdir(\"${bfile}\")\n",
    "    target_all_sample = list(filter(lambda v: re.match('.*wig$', v), target_all_sample))\n",
    "    target_all_sample = [\"${bfile}\" + \"/\" + w for w in target_all_sample]\n",
    "    #print(target_all_sample)\n",
    "    print(\"INFO: Total\",len(target_all_sample),\"samples found in provided dirctory!\")\n",
    "    # Total depth file:\n",
    "    chr = []\n",
    "    for i in range(22):\n",
    "        chr.append(str(i+1))\n",
    "    chr = chr + [\"X\",\"Y\"]\n",
    "    if \"${no_chr_prefix}\" == \"F\":\n",
    "        chr = ['chr' + str(a) for a in chr]\n",
    "    mapping_file = open(\"${_output[0]}\", \"w\")\n",
    "    for current_sample in target_all_sample:\n",
    "        current_sample_total_depth = 0\n",
    "        # skip the default type = bedgraph line\n",
    "        for line in open(current_sample,'r'):\n",
    "            if line[0] != '#' and line[0] != 't':\n",
    "                fields = line.strip('\\n').split('\\t')\n",
    "                curr_chr = fields[0]\n",
    "                region_start = int(fields[1])\n",
    "                region_end = int(fields[2])\n",
    "                current_sample_total_depth += (curr_chr in chr) * int(float(fields[-1])) * (region_end - region_start)\n",
    "        field_out = [current_sample, str(current_sample_total_depth)]\n",
    "        mapping_file.writelines('\\t'.join(field_out) + '\\n')\n",
    "\n",
    "        print(\"Coverage of sample \", current_sample, \": \", current_sample_total_depth)\n",
    "    mapping_file.close()\n",
    "\n",
    "    # Configuration file:\n",
    "\n",
    "    config_file = open(${_output[1]:r},\"w\")\n",
    "    config_file.writelines(f\"Annotated_3UTR=${annotation}\\n\")\n",
    "    config_file.writelines( \"Aligned_Wig_files=%s\\n\" % \",\".join(target_all_sample))\n",
    "    config_file.writelines(f\"Output_directory=../../../../../MWE_dapars2/Output/Wigfiles\\n\")\n",
    "    config_file.writelines(f\"Output_result_file=Dapars_result\\n\")\n",
    "    config_file.writelines(f\"Least_pass_coverage_percentage=${least_pass_coverage_percentage}\\n\")\n",
    "    config_file.writelines( \"Coverage_threshold=${coverage_threshold}\\n\")\n",
    "    config_file.writelines( \"Num_Threads=${thread}\\n\")\n",
    "    config_file.writelines(f\"sequencing_depth_file=${_output[0]}\") \n",
    "    config_file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-design",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step2: Run Dapars2 main to calculate PDUIs\n",
    "#### Tip: modified Dapars2_Multi_Sample.py\n",
    "Default input of Dapars2_Multi_Sample.py did not consider the situation that first column did not contain \"chr\" (shown in _Step 2_).   \n",
    "* We add a new argument no_chr_prefix (default is FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "moving-leader",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Call Dapars2 multi_chromosome\n",
    "[APAmain]\n",
    "parameter: no_chr_prefix = \"T\"\n",
    "parameter: chrlist = list\n",
    "input: for_each = 'chrlist'\n",
    "output: [f'{cwd}/Wigfiles_{x}/Dapars_result_result_temp.{x}.txt' for x in chrlist], group_by = 1\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = ncore\n",
    "bash: expand = True, container = container\n",
    "    python2 ../../../code/Dapars2_Multi_Sample.py {cwd}/sample_configuration_file.txt {_chrlist} {no_chr_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-shark",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step3: Inpute the result:\n",
    "This step impute the missing value in PDUI matrix and return the Imputed one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "checked-brake",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Dapars result Imputation \n",
    "[APAimpute]\n",
    "# Input path\n",
    "# parameter: dapars_raw = \n",
    "parameter: chrlist = list\n",
    "# Default k neighbours. Set k = 0 will train the k in a data-driven manner\n",
    "parameter: knn = 8\n",
    "input: [f'{cwd}/Wigfiles_{x}/Dapars_result_result_temp.{x}.txt' for x in chrlist], group_by = 1\n",
    "output: [f'{cwd}/Dapars_result_imputed_{x}.txt' for x in chrlist], group_by = 1\n",
    "R: expand= \"${ }\", container = container\n",
    "\n",
    ".libPaths( c('/usr/local/lib/R/site-library' , '/usr/lib/R/site-library', '/usr/lib/R/library', .libPaths()))\n",
    "suppressPackageStartupMessages(require(dplyr))\n",
    "suppressPackageStartupMessages(require(tidyr))\n",
    "suppressPackageStartupMessages(require(doParallel))\n",
    "suppressPackageStartupMessages(require(VIM))\n",
    "suppressPackageStartupMessages(require(preprocessCore))\n",
    "  \n",
    "  \n",
    "# KNN impute\n",
    "\n",
    "# Decide the optimal n if possible. Set the k to 2:#sample \n",
    "# and train a best k. The idea is that, randomly remove \n",
    "# 20% numbers in the full value subset 5 times, calculate \n",
    "# MSE of imputed value by VIM and true value to decide which \n",
    "# k is the optimal one. (an analog from 5 fold CV)\n",
    "  \n",
    "  \n",
    "knn_train_sample <- function(input_df, k_nb){\n",
    "      # Sample data and remove entries\n",
    "      # We must keep 1 full col for impute\n",
    "      dim_df <- dim(input_df)\n",
    "      sample_size <-  round(dim_df[1] * dim_df[2] * 0.2, 0)\n",
    "      row_index <- sample(1:nrow(input_df), sample_size)\n",
    "      col_index <- sample(1:ncol(input_df), sample_size, replace = T)\n",
    "      val_list <- c()\n",
    "      for(i in 1:length(row_index)){\n",
    "        val_list <- c(val_list, input_df[row_index[i], col_index[i]])\n",
    "        input_df[row_index[i], col_index[i]] <- NA\n",
    "      }\n",
    "\n",
    "      # Impute value\n",
    "\n",
    "      impute_data <- VIM::kNN(input_df, k = k_nb)\n",
    "      impute_data <- impute_data[,1:ncol(input_df)]\n",
    "\n",
    "      # Calculate the MSE:\n",
    "      predict_list <- c()\n",
    "      for(i in 1:length(row_index)){\n",
    "        predict_list <- c(predict_list, impute_data[row_index[i], col_index[i]])\n",
    "      }\n",
    "      tss <- sum((predict_list - val_list)^2)\n",
    "      return(tss)\n",
    "}\n",
    "  \n",
    " # Read the data\n",
    "    input_dir <- ${_input:r}\n",
    "  \n",
    "\n",
    "    dapars_result <- \n",
    "      read.table(input_dir,\n",
    "                 header = T) \n",
    "    \n",
    "    dapars_names <- \n",
    "      dapars_result %>% \n",
    "      select(1:3)\n",
    "  \n",
    "    dapars_result <-\n",
    "      dapars_result %>% \n",
    "      select(-1:-3) \n",
    " \n",
    "  if(${knn} == 0){\n",
    "    \n",
    "\n",
    "    dapars_train_data <- dapars_result %>% drop_na()\n",
    "\n",
    "    # Train the model\n",
    "    no_cores <- detectCores() - 1\n",
    "    cl <- makeCluster(no_cores)\n",
    "    registerDoParallel(cl)\n",
    "\n",
    "    index <- seq(2, ncol(dapars_train_data), by = 1)  # Change by = x for precision, for large dataset, please make it bigger\n",
    "    result_list <- c()\n",
    "    for(i in 1:length(index)){\n",
    "        print(paste0(\"Train k = \",index[i]))\n",
    "        re <- foreach(j=1:5,.combine = c) %dopar% \n",
    "          knn_train_sample(dapars_train_data, index[i])\n",
    "        result_list <- c(result_list, mean(re))\n",
    "      }\n",
    "\n",
    "    optimal_k <- index[which.min(result_list)]\n",
    "    print(paste0(\"Optimal k selected is \", optimal_k))\n",
    "    }else{\n",
    "      optimal_k <- ${knn} \n",
    "      print(paste0(\"Use k = \", optimal_k, \" for imputation\"))\n",
    "    }\n",
    "      \n",
    "    \n",
    "  \n",
    "    # Train the whole dataset:\n",
    "    imputed_full_data <- VIM::kNN(dapars_result, k = optimal_k)\n",
    "    imputed_full_data <- imputed_full_data[,1:ncol(dapars_result)]\n",
    "  \n",
    "    qnorm_full_data <- \n",
    "      preprocessCore::normalize.quantiles(as.matrix(imputed_full_data), \n",
    "                                          copy = F)\n",
    "  \n",
    "    final_data <- cbind(dapars_names, qnorm_full_data)\n",
    "    write.table(final_data, file = ${_output:r}, quote = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-conflict",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# Minimum working example\n",
    "### Step 0: 3UTR generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sensitive-radius",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mUTR_generation_1\u001b[0m: Generate the 3UTR region according to the gtf file\n",
      "Done!\n",
      "INFO: \u001b[32mUTR_generation_1\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mUTR_generation_1\u001b[0m output:   \u001b[32m/mnt/mfs/statgen/ls3751/MWE_dapars2/Output/gene_annotation.bed /mnt/mfs/statgen/ls3751/MWE_dapars2/Output/transcript_to_geneName.txt\u001b[0m\n",
      "INFO: Running \u001b[32mUTR_generation_2\u001b[0m: \n",
      "Generating regions ...\n",
      "Total extracted 3' UTR: 140563\n",
      "Finished\n",
      "INFO: \u001b[32mUTR_generation_2\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mUTR_generation_2\u001b[0m output:   \u001b[32m/mnt/mfs/statgen/ls3751/MWE_dapars2/Output/gencode.v19.annotation_3UTR.bed\u001b[0m\n",
      "INFO: Workflow UTR_generation (ID=wf41b62313b6bb15a) is executed successfully with 2 completed steps.\n"
     ]
    }
   ],
   "source": [
    "sos run /mnt/mfs/statgen/ls3751/github/xqtl-pipeline/pipeline/molecular_phenotypes/calling/apa_calling.ipynb UTR_generation \\\n",
    "    --cwd /mnt/mfs/statgen/ls3751/MWE_dapars2/Output \\\n",
    "    --gtf /mnt/mfs/statgen/ls3751/MWE_dapars2/gencode.v19.annotation.gtf \\\n",
    "    --container /mnt/mfs/statgen/ls3751/container/dapars2.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "distinguished-yugoslavia",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/mnt/mfs/statgen/ls3751/MWE_dapars2/Output\u001b[00m\n",
      "├── gencode.v19.annotation_3UTR.bed\n",
      "├── gene_annotation.bed\n",
      "└── transcript_to_geneName.txt\n",
      "\n",
      "0 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "tree /mnt/mfs/statgen/ls3751/MWE_dapars2/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-mirror",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Step 1: Generating config files and calculating sample depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "amber-tutorial",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mAPAconfig\u001b[0m: Calculcate total depth and configuration file\n",
      "INFO: Total 4 samples found in provided dirctory!\n",
      "Coverage of sample  /mnt/mfs/statgen/ls3751/MWE_dapars2/sample4.wig :  5943757290\n",
      "Coverage of sample  /mnt/mfs/statgen/ls3751/MWE_dapars2/sample3.wig :  6060347021\n",
      "Coverage of sample  /mnt/mfs/statgen/ls3751/MWE_dapars2/sample2.wig :  3617065465\n",
      "Coverage of sample  /mnt/mfs/statgen/ls3751/MWE_dapars2/sample1.wig :  2573149742\n",
      "INFO: \u001b[32mAPAconfig\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mAPAconfig\u001b[0m output:   \u001b[32m/mnt/mfs/statgen/ls3751/MWE_dapars2/Output/sample_mapping_files.txt /mnt/mfs/statgen/ls3751/MWE_dapars2/Output/sample_configuration_file.txt\u001b[0m\n",
      "INFO: Workflow APAconfig (ID=wdc3865265bf562ea) is executed successfully with 1 completed step.\n"
     ]
    }
   ],
   "source": [
    "sos run /mnt/mfs/statgen/ls3751/github/xqtl-pipeline/pipeline/molecular_phenotypes/calling/apa_calling.ipynb APAconfig \\\n",
    "    --cwd /mnt/mfs/statgen/ls3751/MWE_dapars2/Output \\\n",
    "    --bfile /mnt/mfs/statgen/ls3751/MWE_dapars2 \\\n",
    "    --annotation /mnt/mfs/statgen/ls3751/MWE_dapars2/Output/gencode.v19.annotation_3UTR.bed \\\n",
    "    --no_chr_prefix T \\\n",
    "    --container /mnt/mfs/statgen/ls3751/container/dapars2.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bored-tennis",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/mnt/mfs/statgen/ls3751/MWE_dapars2/Output\u001b[00m\n",
      "├── gencode.v19.annotation_3UTR.bed\n",
      "├── gene_annotation.bed\n",
      "├── sample_configuration_file.txt\n",
      "├── sample_mapping_files.txt\n",
      "└── transcript_to_geneName.txt\n",
      "\n",
      "0 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "tree /mnt/mfs/statgen/ls3751/MWE_dapars2/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-bracelet",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Dapars2 Main\n",
    "Note: the example is a truncated version, which just have coverage in chr1,chr11 and chr12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sensitive-bonus",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mAPAmain\u001b[0m: Call Dapars2 multi_chromosome\n",
      "[Sun Jan 30 04:15:34 2022] Start Analysis ...\n",
      "All samples Joint Processing chr1 ...\n",
      "[Sun Jan 30 04:15:34 2022] Loading Coverage ...\n",
      "/mnt/mfs/statgen/ls3751/MWE_dapars2/sample4.wig\n",
      "/mnt/mfs/statgen/ls3751/MWE_dapars2/sample3.wig\n",
      "/mnt/mfs/statgen/ls3751/MWE_dapars2/sample2.wig\n",
      "/mnt/mfs/statgen/ls3751/MWE_dapars2/sample1.wig\n",
      "[5943757290 6060347021 3617065465 2573149742]\n",
      "[Sun Jan 30 04:15:46 2022] Loading Coverage Finished ...\n",
      "#assigned events:\n",
      "1379\n",
      "1379\n",
      "1379\n",
      "1379\n",
      "1379\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "[Sun Jan 30 04:15:51 2022] Finished!\n",
      "INFO: \u001b[32mAPAmain\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mAPAmain\u001b[0m output:   \u001b[32m/mnt/mfs/statgen/ls3751/MWE_dapars2/Output/Wigfiles_chr1/Dapars_result_result_temp.chr1.txt\u001b[0m\n",
      "INFO: Workflow APAmain (ID=w28477dad0713d81d) is executed successfully with 1 completed step.\n"
     ]
    }
   ],
   "source": [
    "sos run /mnt/mfs/statgen/ls3751/github/xqtl-pipeline/pipeline/molecular_phenotypes/calling/apa_calling.ipynb APAmain \\\n",
    "    --cwd /mnt/mfs/statgen/ls3751/MWE_dapars2/Output \\\n",
    "    --no_chr_prefix T \\\n",
    "    --chrlist chr1 \\\n",
    "    --container /mnt/mfs/statgen/ls3751/container/dapars2.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "paperback-miller",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/mnt/mfs/statgen/ls3751/MWE_dapars2/Output\u001b[00m\n",
      "├── gencode.v19.annotation_3UTR.bed\n",
      "├── gene_annotation.bed\n",
      "├── sample_configuration_file.txt\n",
      "├── sample_mapping_files.txt\n",
      "├── transcript_to_geneName.txt\n",
      "└── \u001b[01;34mWigfiles_chr1\u001b[00m\n",
      "    ├── Dapars_result_result_temp.chr1.txt\n",
      "    └── \u001b[01;34mtmp\u001b[00m\n",
      "        ├── Each_processor_3UTR_Result_1.txt\n",
      "        ├── Each_processor_3UTR_Result_2.txt\n",
      "        ├── Each_processor_3UTR_Result_3.txt\n",
      "        ├── Each_processor_3UTR_Result_4.txt\n",
      "        ├── Each_processor_3UTR_Result_5.txt\n",
      "        ├── Each_processor_3UTR_Result_6.txt\n",
      "        ├── Each_processor_3UTR_Result_7.txt\n",
      "        └── Each_processor_3UTR_Result_8.txt\n",
      "\n",
      "2 directories, 14 files\n"
     ]
    }
   ],
   "source": [
    "tree /mnt/mfs/statgen/ls3751/MWE_dapars2/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-slide",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Step 3: Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "saving-accommodation",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mAPAimpute\u001b[0m: Dapars result Imputation\n",
      "Warning message:\n",
      "package ‘VIM’ was built under R version 4.0.5 \n",
      "[1] \"Use k = 5 for imputation\"\n",
      "Error in preprocessCore::normalize.quantiles(as.matrix(imputed_full_data),  : \n",
      "  ERROR; return code from pthread_create() is 22\n",
      "In addition: Warning message:\n",
      "In preprocessCore::normalize.quantiles(as.matrix(imputed_full_data),  :\n",
      "  NAs introduced by coercion\n",
      "Execution halted\n",
      "\u001b[91mERROR\u001b[0m: \u001b[91mAPAimpute (id=9d62c6b78d820375) returns an error.\u001b[0m\n",
      "\u001b[91mERROR\u001b[0m: \u001b[91m[APAimpute]: [0]: Executing script in Singularity returns an error (exitcode=1).\n",
      "The script has been saved to /home/ls3751/.sos/a23a325a1ed7f8c9/singularity_run_19849.R. To reproduce the error please run:\n",
      "\u001b[0m\u001b[32msingularity exec  /mnt/mfs/statgen/ls3751/container/dapars2.sif Rscript /home/ls3751/.sos/a23a325a1ed7f8c9/singularity_run_19849.R\u001b[0m\u001b[91m\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "sos run /mnt/mfs/statgen/ls3751/github/xqtl-pipeline/pipeline/molecular_phenotypes/calling/apa_calling.ipynb APAimpute \\\n",
    "    --cwd /mnt/mfs/statgen/ls3751/MWE_dapars2/Output \\\n",
    "    --chrlist chr1 \\\n",
    "    --container /mnt/mfs/statgen/ls3751/container/dapars2.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-concord",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
