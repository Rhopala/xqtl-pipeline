{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spare-platinum",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Multivariate SuSiE and FastENLOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-respect",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Aim:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-arabic",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook aims to demonstrate a workflow of generating posterior inclusion probabilities (PIPs) from GWAS summary statistics using SuSiE linear regression and construsting SNP signal clusters from global eQTL analysis data obtained from multivariate SuSiE models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-salmon",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Input:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-ribbon",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1) GWAS Summary Statistics with the following columns:\n",
    "- chr: chromosome number\n",
    "- bp: base pair position\n",
    "- a1: effect allele\n",
    "- a2: other allele\n",
    "- beta: effect size\n",
    "- se: standard error of beta\n",
    "- z: z score\n",
    "\n",
    "2) eQTL data from multivariate SuSiE model with the following columns:\n",
    "- chr: chromosome number\n",
    "- bp: base pair position\n",
    "- a1: effect allele\n",
    "- a2: other allele\n",
    "- pip: posterior inclusion probability\n",
    "\n",
    "3) LD correlation matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-artist",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-folks",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Intermediate files:\n",
    "\n",
    "1) GWAS PIP file \n",
    "\n",
    "2) eQTL annotation file\n",
    "\n",
    "Final Outputs:\n",
    "\n",
    "1) Enrichment analysis result prefix.enloc.enrich.rst: estimated enrichment parameters and standard errors.\n",
    "\n",
    "2) Signal-level colocalization result prefix.enloc.sig.out: the main output from the colocalization analysis with the following format\n",
    "- column 1: signal cluster name (from eQTL analysis)\n",
    "- column 2: number of member SNPs\n",
    "- column 3: cluster PIP of eQTLs\n",
    "- column 4: cluster PIP of GWAS hits (without eQTL prior)\n",
    "- column 5: cluster PIP of GWAS hits (with eQTL prior)\n",
    "- column 6: regional colocalization probability (RCP)\n",
    "\n",
    "3) SNP-level colocalization result prefix.enloc.snp.out: SNP-level colocalization output with the following form at\n",
    "- column 1: signal cluster name\n",
    "- column 2: SNP name\n",
    "- column 3: SNP-level PIP of eQTLs\n",
    "- column 4: SNP-level PIP of GWAS (without eQTL prior)\n",
    "- column 5: SNP-level PIP of GWAS (with eQTL prior)\n",
    "- column 6: SNP-level colocalization probability\n",
    "\n",
    "4) Sorted list of colocalization signals with\n",
    "`sort -grk6 prefix.enloc.sig.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-green",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-appliance",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-composite",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### 1) Allele Flip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-pacific",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Takes into consideration 3 situations: \n",
    "\n",
    "1) \"Major\" and \"minor\" alleles flipped\n",
    "\n",
    "2) Different strand but same variant\n",
    "\n",
    "3) Remove variants with A/T and C/G alleles due to ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-pharmacy",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(devtools)\n",
    "library(susieR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-northwest",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "\n",
    "allele.qc = function(a1,a2,ref1,ref2) {\n",
    "\t# a1 and a2 are the first data-set\n",
    "\t# ref1 and ref2 are the 2nd data-set\n",
    "\t# Make all the alleles into upper-case, as A,T,C,G:\n",
    "        a1 = toupper(a1)\n",
    "        a2 = toupper(a2)\n",
    "        ref1 = toupper(ref1)\n",
    "        ref2 = toupper(ref2)\n",
    "\t# Strand flip, to change the allele representation in the 2nd data-set\n",
    "\tstrand_flip = function(ref) {\n",
    "\t\tflip = ref\n",
    "\t\tflip[ref == \"A\"] = \"T\"\n",
    "\t\tflip[ref == \"T\"] = \"A\"\n",
    "\t\tflip[ref == \"G\"] = \"C\"\n",
    "\t\tflip[ref == \"C\"] = \"G\"\n",
    "\t\tflip\n",
    "\t}\n",
    "\tflip1 = strand_flip(ref1)\n",
    "\tflip2 = strand_flip(ref2)\n",
    "\tsnp = list()\n",
    "\t# Remove strand ambiguous SNPs (scenario 3)\n",
    "\tsnp[[\"keep\"]] = !((a1==\"A\" & a2==\"T\") | (a1==\"T\" & a2==\"A\") | (a1==\"C\" & a2==\"G\") | (a1==\"G\" & a2==\"C\"))\n",
    "\t# Remove non-ATCG coding\n",
    "\tsnp[[\"keep\"]][ a1 != \"A\" & a1 != \"T\" & a1 != \"G\" & a1 != \"C\" ] = F\n",
    "\tsnp[[\"keep\"]][ a2 != \"A\" & a2 != \"T\" & a2 != \"G\" & a2 != \"C\" ] = F\n",
    "\t# as long as scenario 1 is involved, sign_flip will return TRUE\n",
    "\tsnp[[\"sign_flip\"]] = (a1 == ref2 & a2 == ref1) | (a1 == flip2 & a2 == flip1)\n",
    "\t# as long as scenario 2 is involved, strand_flip will return TRUE\n",
    "\tsnp[[\"strand_flip\"]] = (a1 == flip1 & a2 == flip2) | (a1 == flip2 & a2 == flip1)\n",
    "\t# remove other cases, eg, tri-allelic, one dataset is A C, the other is A G, for example.\n",
    "\texact_match = (a1 == ref1 & a2 == ref2) \n",
    "\tsnp[[\"keep\"]][!(exact_match | snp[[\"sign_flip\"]] | snp[[\"strand_flip\"]])] = F\n",
    "\treturn(snp)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-lloyd",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### 2) Construct eQTL data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-murray",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "eqtl.split = function(eqtl){\n",
    "  rows = length(eqtl)\n",
    "  chr = vector(length = rows)\n",
    "  pos = vector(length = rows)\n",
    "  a1 = vector(length = rows)\n",
    "  a2 = vector(length = rows)\n",
    "  for (i in 1:rows){\n",
    "    split1 = str_split(eqtl[i], \":\")\n",
    "    split2 = str_split(split1[[1]][2], \"_\")\n",
    "    chr[i]= split1[[1]][1]\n",
    "    pos[i] = split2[[1]][1]\n",
    "    a1[i] = split2[[1]][2]\n",
    "    a2[i] = split2[[1]][3]\n",
    "\n",
    "  }\n",
    "  eqtl.df = data.frame(eqtl,chr,pos,a1,a2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-lincoln",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### 3) Remove Duplicate variants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-universal",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "remove.dup = function(df){\n",
    "  df = df %>% arrange(PosGRCh37, -N)\n",
    "  df = df[!duplicated(df$PosGRCh37),]\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-landing",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### 4) Construct signal clusters (LD $R^{2}$ threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-challenge",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "greedy = function(alpha) {\n",
    "  len = length(alpha)\n",
    "  r2 = 0.5\n",
    "  c_r2 = 1\n",
    "  ids = vector()\n",
    "  first = 1\n",
    "  less = 0\n",
    "  total = 0\n",
    "  for (i in 1:len) {\n",
    "    max = max(alpha)\n",
    "    total = total + max\n",
    "    idx = which.max(alpha)\n",
    "    if (length(ids) == 0) {\n",
    "      ids = append(ids, idx)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for (j in 1:length(ids)) {\n",
    "      new_r2 = (ld_f2[ids[j], idx]) ^ 2\n",
    "      # print(new_r2)\n",
    "      if (new_r2 < r2) {\n",
    "        less = 1\n",
    "        break\n",
    "      }\n",
    "      else{\n",
    "        c_r2 = new_r2\n",
    "      }\n",
    "      \n",
    "    }\n",
    "    \n",
    "    if (less == 1) {\n",
    "      total = total - max\n",
    "      break\n",
    "    }\n",
    "    \n",
    "    if (first == 0) {\n",
    "      ids = append(ids, idx)\n",
    "    }\n",
    "    \n",
    "    alpha[idx] = 0\n",
    "    first = 0\n",
    "    \n",
    "  }\n",
    "  return(list(ids, total, c_r2))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-costa",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-territory",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### Step 1: Extract common SNPS between the GWAS summary statistics and eQTL data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-albuquerque",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# eqtl\n",
    "load(file.choose())\n",
    "eqtl = gene.name\n",
    "\n",
    "# colnames\n",
    "load(\"path/to/scaled/gene\")\n",
    "var = colnames(scaled.gene)\n",
    "\n",
    "#ld\n",
    "ld = readRDS(file.choose())\n",
    "\n",
    "# initial filter of gwas variants that are in eqtl\n",
    "gwas_filter = gwas[which(gwas$id %in% var),]\n",
    "\n",
    "# create eqtl df\n",
    "eqtl.df = eqtl.split(var)\n",
    "\n",
    "# allele flip\n",
    "f_gwas = gwas %>% filter(chr %in% eqtl.df$chr & PosGRCh37 %in% eqtl.df$pos)\n",
    "eqtl.df.f = eqtl.df %>% filter(pos %in% f_gwas$PosGRCh37)\n",
    "\n",
    "# check if there are duplicate pos\n",
    "length(unique(f_gwas$PosGRCh37))\n",
    "\n",
    "# multiple snps with same pos\n",
    "dup.pos = f_gwas %>% group_by(PosGRCh37) %>% filter(n() > 1) \n",
    "\n",
    "f_gwas = remove.dup(f_gwas)\n",
    "\n",
    "qc = allele.qc(f_gwas$testedAllele, f_gwas$otherAllele, eqtl.df.f$a1, eqtl.df.f$a2)\n",
    "keep = as.data.frame(qc$keep)\n",
    "sign = as.data.frame(qc$sign_flip)\n",
    "strand = as.data.frame(qc$strand_flip)\n",
    "\n",
    "# sign flip\n",
    "f_gwas$z[qc$sign_flip] = -1 * f_gwas$z[qc$sign_flip]\n",
    "f_gwas$testedAllele[qc$sign_flip] = eqtl.df.f$a1[qc$sign_flip]\n",
    "f_gwas$otherAllele[qc$sign_flip] = eqtl.df.f$a2[qc$sign_flip]\n",
    "\n",
    "f_gwas$testedAllele[qc$strand_flip] = eqtl.df.f$a1[qc$strand_flip]\n",
    "f_gwas$otherAllele[qc$strand_flip] = eqtl.df.f$a2[qc$strand_flip]\n",
    "\n",
    "# remove ambigiuous \n",
    "if ( sum(!qc$keep) > 0 ) {\n",
    "  eqtl.df.f = eqtl.df.f[qc$keep,]\n",
    "  f_gwas = f_gwas[qc$keep,]\n",
    "}\n",
    "\n",
    "# lds filtered\n",
    "eqtl_id = which(var %in% eqtl.df.f$eqtl)\n",
    "ld_f = ld[eqtl_id, eqtl_id]\n",
    "\n",
    "# ld missing\n",
    "miss = which(is.na(ld_f), arr.ind=TRUE)\n",
    "\n",
    "miss_r = unique(as.data.frame(miss)$row)\n",
    "miss_c = unique(as.data.frame(miss)$col)\n",
    "\n",
    "total_miss = unique(union(miss_r,miss_c))\n",
    "\n",
    "if(length(total_miss) != 0){ \n",
    "eqtl_id.f = eqtl.df.f[-total_miss,]\n",
    "}else{eqtl_id.f = eqtl.df.f}\n",
    "\n",
    "# rename ids\n",
    "\n",
    "f_gwas = f_gwas %>% mutate(id = paste(f_gwas$chr, paste(f_gwas$PosGRCh37, f_gwas$testedAllele, f_gwas$otherAllele, sep = \"_\"), sep = \":\"))\n",
    "\n",
    "f_gwas.f = f_gwas %>% filter(id %in% eqtl_id.f$eqtl)\n",
    "\n",
    "\n",
    "if (length(total_miss)!=0){\n",
    "ld_f2 = ld_f[-total_miss,]\n",
    "ld_f2 = ld_f2[,-total_miss]\n",
    "dim(ld_f2)\n",
    "}else{ld_f2 = ld_f}\n",
    "\n",
    "miss = which(is.na(ld_f2), arr.ind=TRUE)\n",
    "\n",
    "# remove multi-allelic snps that aren't present in both eqtl and gwas \n",
    "\n",
    "idx = which(eqtl_id.f$eqtl %notin% f_gwas$id)\n",
    "if(length(idx) != 0){\n",
    "eqtl_id.f = eqtl_id.f[-idx,]\n",
    "ld_f2 = ld_f2[-idx,]\n",
    "ld_f2 = ld_f2[,-idx]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-venue",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### Step 2: Obtain SNP PIPs from GWAS summary statistics using SuSiE linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-geology",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "susie_results = susieR::susie_rss(z = f_gwas.f$z,R = ld_f2, check_prior = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-wisconsin",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# susieR::susie_plot(susie_results,\"PIP\")\n",
    "# susie_results$z = f_gwas.f$z\n",
    "# susieR::susie_plot(susie_results,\"z_original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-chemistry",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "gwas.annot = cbind(f_gwas.f,susie_results$pip)\n",
    "write.table(gwas.annot, file = \"gwas.pip.txt\", col.names = F, row.names = F, quote = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-header",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### Step 3: Construct signal clusters using eQTL SNP PIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-success",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "pip = eqtl$pip[o_id]\n",
    "eqtl_annot = cbind(eqtl_id.f, pip) %>% mutate(gene = gene.name,cluster = -1, cluster_pip = 0, total_snps = 0)\n",
    "\n",
    "clusters = data.frame(grp = numeric(), total_snp = character(), cluster_pip = numeric(), avg_r = numeric())\n",
    "zero = vector()\n",
    "for(al in 1:10){\n",
    "  if(length(zero) != 0){\n",
    "    alpha[,zero] = 0\n",
    "  }\n",
    "  a = greedy(alpha[al,])\n",
    "  for(snp in a[[1]]){\n",
    "    zero = append(zero,snp)\n",
    "    eqtl_annot$cluster[snp] = al\n",
    "    eqtl_annot$cluster_pip[snp] = a[[2]]\n",
    "    eqtl_annot$total_snps[snp] = length(a[[1]])\n",
    "  } \n",
    "  clusters = rbind(clusters, data.frame(grp = al, total_snp = length(a[[1]]), cluster_pip = a[[2]], avg_r = a[[3]]))\n",
    "}\n",
    "\n",
    "eqtl_annot = eqtl_annot %>% filter(cluster != -1) %>% \n",
    "  mutate(annot = sprintf(\"%s:%d@=%e[%e:%d]\",gene,cluster,pip,cluster_pip,total_snps)) %>%\n",
    "  select(c(chr,pos,eqtl,a1,a2,annot))  \n",
    "\n",
    "write.table(eqtl_annot, file = \"eqtl.annot.txt\", col.names = T, row.names = F, quote = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-richmond",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### Step 4: Colocalization with FastEnloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-coverage",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "gzip gwas.pip.txt\n",
    "gzip eqtl.annot.txt\n",
    "fastenloc -eqtl eqtl.annot.txt.gz -gwas gwas.pip.txt.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-conversion",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Minimal Working Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-finland",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# eqtl\n",
    "load(file.choose())\n",
    "eqtl = m_ENSG00000159640\n",
    "\n",
    "# colnames\n",
    "load(\"geneTpmResidualsAgeGenderAdj_rename.ENSG00000159640.transformed_XY.RData\")\n",
    "var = colnames(scaled_ENSG00000159640[[1]])\n",
    "\n",
    "#ld\n",
    "ld = readRDS(file.choose())\n",
    "\n",
    "# initial filter of gwas variants that are in eqtl\n",
    "gwas_filter = gwas[which(gwas$id %in% var),]\n",
    "\n",
    "# create eqtl df\n",
    "eqtl.df = eqtl.split(var)\n",
    "\n",
    "# allele flip\n",
    "f_gwas = gwas %>% filter(chr %in% eqtl.df$chr & PosGRCh37 %in% eqtl.df$pos)\n",
    "eqtl.df.f = eqtl.df %>% filter(pos %in% f_gwas$PosGRCh37)\n",
    "\n",
    "# check if there are duplicate pos\n",
    "length(unique(f_gwas$PosGRCh37))\n",
    "\n",
    "# multiple snps with same pos\n",
    "dup.pos = f_gwas %>% group_by(PosGRCh37) %>% filter(n() > 1) \n",
    "\n",
    "f_gwas = remove.dup(f_gwas)\n",
    "\n",
    "qc = allele.qc(f_gwas$testedAllele, f_gwas$otherAllele, eqtl.df.f$a1, eqtl.df.f$a2)\n",
    "keep = as.data.frame(qc$keep)\n",
    "sign = as.data.frame(qc$sign_flip)\n",
    "strand = as.data.frame(qc$strand_flip)\n",
    "\n",
    "# sign flip\n",
    "f_gwas$z[qc$sign_flip] = -1 * f_gwas$z[qc$sign_flip]\n",
    "f_gwas$testedAllele[qc$sign_flip] = eqtl.df.f$a1[qc$sign_flip]\n",
    "f_gwas$otherAllele[qc$sign_flip] = eqtl.df.f$a2[qc$sign_flip]\n",
    "\n",
    "f_gwas$testedAllele[qc$strand_flip] = eqtl.df.f$a1[qc$strand_flip]\n",
    "f_gwas$otherAllele[qc$strand_flip] = eqtl.df.f$a2[qc$strand_flip]\n",
    "\n",
    "# remove ambigiuous \n",
    "if ( sum(!qc$keep) > 0 ) {\n",
    "  eqtl.df.f = eqtl.df.f[qc$keep,]\n",
    "  f_gwas = f_gwas[qc$keep,]\n",
    "}\n",
    "\n",
    "# lds filtered\n",
    "eqtl_id = which(var %in% eqtl.df.f$eqtl)\n",
    "ld_f = ld[eqtl_id, eqtl_id]\n",
    "\n",
    "# ld missing\n",
    "miss = which(is.na(ld_f), arr.ind=TRUE)\n",
    "\n",
    "miss_r = unique(as.data.frame(miss)$row)\n",
    "miss_c = unique(as.data.frame(miss)$col)\n",
    "\n",
    "total_miss = unique(union(miss_r,miss_c))\n",
    "\n",
    "if(length(total_miss) != 0){ \n",
    "eqtl_id.f = eqtl.df.f[-total_miss,]\n",
    "}else{eqtl_id.f = eqtl.df.f}\n",
    "\n",
    "# rename ids\n",
    "\n",
    "f_gwas = f_gwas %>% mutate(id = paste(f_gwas$chr, paste(f_gwas$PosGRCh37, f_gwas$testedAllele, f_gwas$otherAllele, sep = \"_\"), sep = \":\"))\n",
    "\n",
    "f_gwas.f = f_gwas %>% filter(id %in% eqtl_id.f$eqtl)\n",
    "\n",
    "\n",
    "if (length(total_miss)!=0){\n",
    "ld_f2 = ld_f[-total_miss,]\n",
    "ld_f2 = ld_f2[,-total_miss]\n",
    "dim(ld_f2)\n",
    "}else{ld_f2 = ld_f}\n",
    "\n",
    "miss = which(is.na(ld_f2), arr.ind=TRUE)\n",
    "\n",
    "# remove multi-allelic snps that aren't present in both eqtl and gwas \n",
    "\n",
    "idx = which(eqtl_id.f$eqtl %notin% f_gwas$id)\n",
    "if(length(idx) != 0){\n",
    "eqtl_id.f = eqtl_id.f[-idx,]\n",
    "ld_f2 = ld_f2[-idx,]\n",
    "ld_f2 = ld_f2[,-idx]\n",
    "}\n",
    "\n",
    "susie_results = susieR::susie_rss(z = f_gwas.f$z,R = ld_f2, check_prior = F)\n",
    "gwas.annot = cbind(f_gwas.f,susie_results$pip)\n",
    "write.table(gwas.annot, file = \"gwas.pip.txt\", col.names = F, row.names = F, quote = F)\n",
    "\n",
    "pip = eqtl$pip[o_id]\n",
    "eqtl_annot = cbind(eqtl_id.f, pip) %>% mutate(gene =\" ENSG00000159640\",cluster = -1, cluster_pip = 0, total_snps = 0)\n",
    "\n",
    "clusters = data.frame(grp = numeric(), total_snp = character(), cluster_pip = numeric(), avg_r = numeric())\n",
    "zero = vector()\n",
    "for(al in 1:10){\n",
    "  if(length(zero) != 0){\n",
    "    alpha[,zero] = 0\n",
    "  }\n",
    "  a = greedy(alpha[al,])\n",
    "  for(snp in a[[1]]){\n",
    "    zero = append(zero,snp)\n",
    "    eqtl_annot$cluster[snp] = al\n",
    "    eqtl_annot$cluster_pip[snp] = a[[2]]\n",
    "    eqtl_annot$total_snps[snp] = length(a[[1]])\n",
    "  } \n",
    "  clusters = rbind(clusters, data.frame(grp = al, total_snp = length(a[[1]]), cluster_pip = a[[2]], avg_r = a[[3]]))\n",
    "}\n",
    "\n",
    "eqtl_annot = eqtl_annot %>% filter(cluster != -1) %>% \n",
    "  mutate(annot = sprintf(\"%s:%d@=%e[%e:%d]\",gene,cluster,pip,cluster_pip,total_snps)) %>%\n",
    "  select(c(chr,pos,eqtl,a1,a2,annot))  \n",
    "\n",
    "write.table(eqtl_annot, file = \"ENSG00000159640.annot.txt\", col.names = T, row.names = F, quote = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-actress",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "gzip gwas.pip.txt\n",
    "gzip ENSG00000159640.annot.txt\n",
    "fastenloc -eqtl ENSG00000159640.annot.txt.gz -gwas gwas.pip.txt.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-being",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-richardson",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "susieR::susie_plot(susie_results,\"PIP\")\n",
    "susie_results$z = f_gwas.f$z\n",
    "susieR::susie_plot(susie_results,\"z_original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-oriental",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "eqtl_annot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-cancellation",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-airplane",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.enrich.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-pencil",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.sig.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-harassment",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.snp.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
