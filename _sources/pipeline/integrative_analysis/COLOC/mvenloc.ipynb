{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adequate-winter",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Multivariate colocalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-vancouver",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Aim:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-charger",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook aims to demonstrate a workflow of generating posterior inclusion probabilities (PIPs) from GWAS summary statistics using SuSiE linear regression and construsting SNP signal clusters from global eQTL analysis data obtained from multivariate SuSiE models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-bacon",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Input:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-forest",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1) GWAS Summary Statistics with the following columns:\n",
    "- chr: chromosome number\n",
    "- bp: base pair position\n",
    "- a1: effect allele\n",
    "- a2: other allele\n",
    "- beta: effect size\n",
    "- se: standard error of beta\n",
    "- z: z score\n",
    "\n",
    "2) eQTL data from multivariate SuSiE model with the following columns:\n",
    "- chr: chromosome number\n",
    "- bp: base pair position\n",
    "- a1: effect allele\n",
    "- a2: other allele\n",
    "- pip: posterior inclusion probability\n",
    "\n",
    "3) LD correlation matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-crown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-bloom",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Intermediate files:\n",
    "\n",
    "1) GWAS PIP file \n",
    "\n",
    "2) eQTL annotation file\n",
    "\n",
    "Final Outputs:\n",
    "\n",
    "1) Enrichment analysis result prefix.enloc.enrich.rst: estimated enrichment parameters and standard errors.\n",
    "\n",
    "2) Signal-level colocalization result prefix.enloc.sig.out: the main output from the colocalization analysis with the following format\n",
    "- column 1: signal cluster name (from eQTL analysis)\n",
    "- column 2: number of member SNPs\n",
    "- column 3: cluster PIP of eQTLs\n",
    "- column 4: cluster PIP of GWAS hits (without eQTL prior)\n",
    "- column 5: cluster PIP of GWAS hits (with eQTL prior)\n",
    "- column 6: regional colocalization probability (RCP)\n",
    "\n",
    "3) SNP-level colocalization result prefix.enloc.snp.out: SNP-level colocalization output with the following form at\n",
    "- column 1: signal cluster name\n",
    "- column 2: SNP name\n",
    "- column 3: SNP-level PIP of eQTLs\n",
    "- column 4: SNP-level PIP of GWAS (without eQTL prior)\n",
    "- column 5: SNP-level PIP of GWAS (with eQTL prior)\n",
    "- column 6: SNP-level colocalization probability\n",
    "\n",
    "4) Sorted list of colocalization signals with\n",
    "`sort -grk6 prefix.enloc.sig.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-segment",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-bhutan",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-navigation",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### 1) Allele Flip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-invalid",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Takes into consideration 3 situations: \n",
    "\n",
    "1) \"Major\" and \"minor\" alleles flipped\n",
    "\n",
    "2) Different strand but same variant\n",
    "\n",
    "3) Remove variants with A/T and C/G alleles due to ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-hebrew",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "allele.qc = function(a1,a2,ref1,ref2) {\n",
    "\t# a1 and a2 are the first data-set\n",
    "\t# ref1 and ref2 are the 2nd data-set\n",
    "\t# Make all the alleles into upper-case, as A,T,C,G:\n",
    "        a1 = toupper(a1)\n",
    "        a2 = toupper(a2)\n",
    "        ref1 = toupper(ref1)\n",
    "        ref2 = toupper(ref2)\n",
    "\t# Strand flip, to change the allele representation in the 2nd data-set\n",
    "\tstrand_flip = function(ref) {\n",
    "\t\tflip = ref\n",
    "\t\tflip[ref == \"A\"] = \"T\"\n",
    "\t\tflip[ref == \"T\"] = \"A\"\n",
    "\t\tflip[ref == \"G\"] = \"C\"\n",
    "\t\tflip[ref == \"C\"] = \"G\"\n",
    "\t\tflip\n",
    "\t}\n",
    "\tflip1 = strand_flip(ref1)\n",
    "\tflip2 = strand_flip(ref2)\n",
    "\tsnp = list()\n",
    "\t# Remove strand ambiguous SNPs (scenario 3)\n",
    "\tsnp[[\"keep\"]] = !((a1==\"A\" & a2==\"T\") | (a1==\"T\" & a2==\"A\") | (a1==\"C\" & a2==\"G\") | (a1==\"G\" & a2==\"C\"))\n",
    "\t# Remove non-ATCG coding\n",
    "\tsnp[[\"keep\"]][ a1 != \"A\" & a1 != \"T\" & a1 != \"G\" & a1 != \"C\" ] = F\n",
    "\tsnp[[\"keep\"]][ a2 != \"A\" & a2 != \"T\" & a2 != \"G\" & a2 != \"C\" ] = F\n",
    "\t# as long as scenario 1 is involved, sign_flip will return TRUE\n",
    "\tsnp[[\"sign_flip\"]] = (a1 == ref2 & a2 == ref1) | (a1 == flip2 & a2 == flip1)\n",
    "\t# as long as scenario 2 is involved, strand_flip will return TRUE\n",
    "\tsnp[[\"strand_flip\"]] = (a1 == flip1 & a2 == flip2) | (a1 == flip2 & a2 == flip1)\n",
    "\t# remove other cases, eg, tri-allelic, one dataset is A C, the other is A G, for example.\n",
    "\texact_match = (a1 == ref1 & a2 == ref2) \n",
    "\tsnp[[\"keep\"]][!(exact_match | snp[[\"sign_flip\"]] | snp[[\"strand_flip\"]])] = F\n",
    "\treturn(snp)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-olympus",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### 2) Construct eQTL data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-workshop",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "eqtl.split = function(eqtl){\n",
    "  rows = length(eqtl)\n",
    "  chr = vector(length = rows)\n",
    "  pos = vector(length = rows)\n",
    "  a1 = vector(length = rows)\n",
    "  a2 = vector(length = rows)\n",
    "  for (i in 1:rows){\n",
    "    split1 = str_split(eqtl[i], \":\")\n",
    "    split2 = str_split(split1[[1]][2], \"_\")\n",
    "    chr[i]= split1[[1]][1]\n",
    "    pos[i] = split2[[1]][1]\n",
    "    a1[i] = split2[[1]][2]\n",
    "    a2[i] = split2[[1]][3]\n",
    "\n",
    "  }\n",
    "  eqtl.df = data.frame(eqtl,chr,pos,a1,a2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-still",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### 3) Remove Duplicate variants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-identity",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "remove.dup = function(df){\n",
    "  df = df %>% arrange(PosGRCh37, -N)\n",
    "  df = df[!duplicated(df$PosGRCh37),]\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-showcase",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "greedy = function(alpha){\n",
    "  len = length(alpha)\n",
    "  r2 = 0.5\n",
    "  c_r2 = 1\n",
    "  ids = vector()\n",
    "  first = 1\n",
    "  less = 0\n",
    "  total = 0\n",
    "  for(i in 1:len){\n",
    "    max = max(alpha)\n",
    "    total = total + max\n",
    "    idx = which.max(alpha)\n",
    "    if(length(ids) == 0){\n",
    "      ids = append(ids,idx)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for(j in 1:length(ids)){\n",
    "      new_r2 = (ld_f2[ids[j],idx])^2\n",
    "     # print(new_r2)\n",
    "      if(new_r2 < r2){\n",
    "        less = 1\n",
    "        break\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if(less == 1){\n",
    "      break\n",
    "      }\n",
    "    \n",
    "    if(first == 0){\n",
    "    ids = append(ids,idx)\n",
    "    }\n",
    "\n",
    "    alpha = alpha[-idx]\n",
    "    first = 0\n",
    "    \n",
    "  }\n",
    "  return(list(ids, total))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-aviation",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-communications",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(devtools)\n",
    "library(susieR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-forth",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### Step 1: Extract common SNPS between the GWAS summary statistics and eQTL data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-doctor",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# eqtl\n",
    "load(file.choose())\n",
    "eqtl = m_ENSG00000159640\n",
    "\n",
    "# colnames\n",
    "load(\"geneTpmResidualsAgeGenderAdj_rename.ENSG00000159640.transformed_XY.RData\")\n",
    "var = colnames(scaled_ENSG00000159640[[1]])\n",
    "\n",
    "#ld\n",
    "ld = readRDS(file.choose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-imagination",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "gwas_filter = gwas[which(gwas$id %in% var),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-turkish",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "eqtl.df = eqtl.split(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-production",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# allele flip\n",
    "f_gwas = gwas %>% filter(chr %in% eqtl.df$chr & PosGRCh37 %in% eqtl.df$pos)\n",
    "eqtl.df.f = eqtl.df %>% filter(pos %in% f_gwas$PosGRCh37)\n",
    "\n",
    "# check if there are duplicate pos\n",
    "length(unique(f_gwas$PosGRCh37))\n",
    "\n",
    "# multiple snps with same pos\n",
    "dup.pos = f_gwas %>% group_by(PosGRCh37) %>% filter(n() > 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-brush",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "f_gwas = remove.dup(f_gwas)\n",
    "\n",
    "qc = allele.qc(f_gwas$testedAllele, f_gwas$otherAllele, eqtl.df.f$a1, eqtl.df.f$a2)\n",
    "keep = as.data.frame(qc$keep)\n",
    "sign = as.data.frame(qc$sign_flip)\n",
    "strand = as.data.frame(qc$strand_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-lewis",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# sign flip\n",
    "f_gwas$z[qc$sign_flip] = -1 * f_gwas$z[qc$sign_flip]\n",
    "f_gwas$testedAllele[qc$sign_flip] = eqtl.df.f$a1[qc$sign_flip]\n",
    "f_gwas$otherAllele[qc$sign_flip] = eqtl.df.f$a2[qc$sign_flip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-nancy",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "f_gwas$testedAllele[qc$strand_flip] = eqtl.df.f$a1[qc$strand_flip]\n",
    "f_gwas$otherAllele[qc$strand_flip] = eqtl.df.f$a2[qc$strand_flip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-washington",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# remove ambigiuous \n",
    "if ( sum(!qc$keep) > 0 ) {\n",
    "  eqtl.df.f = eqtl.df.f[qc$keep,]\n",
    "  f_gwas = f_gwas[qc$keep,]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-client",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# lds filtered\n",
    "eqtl_id = which(var %in% eqtl.df.f$eqtl)\n",
    "ld_f = ld[eqtl_id, eqtl_id]\n",
    "dim(ld_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-stroke",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "# ld missing\n",
    "\n",
    "miss = which(is.na(ld_f), arr.ind=TRUE)\n",
    "\n",
    "\n",
    "miss_r = unique(as.data.frame(miss)$row)\n",
    "miss_c = unique(as.data.frame(miss)$col)\n",
    "\n",
    "total_miss = unique(union(miss_r,miss_c))\n",
    "\n",
    "if(length(total_miss) != 0){ \n",
    "eqtl_id.f = eqtl.df.f[-total_miss,]\n",
    "}else{eqtl_id.f = eqtl.df.f}\n",
    "\n",
    "# rename ids\n",
    "\n",
    "f_gwas = f_gwas %>% mutate(id = paste(f_gwas$chr, paste(f_gwas$PosGRCh37, f_gwas$testedAllele, f_gwas$otherAllele, sep = \"_\"), sep = \":\"))\n",
    "\n",
    "f_gwas.f = f_gwas %>% filter(id %in% eqtl_id.f$eqtl)\n",
    "\n",
    "\n",
    "if (length(total_miss)!=0){\n",
    "ld_f2 = ld_f[-total_miss,]\n",
    "ld_f2 = ld_f2[,-total_miss]\n",
    "dim(ld_f2)\n",
    "}else{ld_f2 = ld_f}\n",
    "\n",
    "miss = which(is.na(ld_f2), arr.ind=TRUE)\n",
    "\n",
    "# remove multi-allelic snps that aren't present in both eqtl and gwas \n",
    "\n",
    "\n",
    "idx = which(eqtl_id.f$eqtl %notin% f_gwas$id)\n",
    "if(length(idx) != 0){\n",
    "eqtl_id.f = eqtl_id.f[-idx,]\n",
    "ld_f2 = ld_f2[-idx,]\n",
    "ld_f2 = ld_f2[,-idx]\n",
    "}\n",
    "dim(ld_f2)\n",
    "dim(eqtl_id.f)\n",
    "dim(f_gwas.f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-celtic",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### Step 2: Obtain SNP PIPs from GWAS summary statistics using SuSiE linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-bibliography",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "susie_results = susieR::susie_rss(z = f_gwas.f$z,R = ld_f2, check_prior = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-dancing",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "susieR::susie_plot(susie_results,\"PIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-noise",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "susie_results$z = f_gwas.f$z\n",
    "susieR::susie_plot(susie_results,\"z_original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-despite",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "#### Step 3: Construct signal clusters using eQTL SNP PIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-reading",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "for( al in 1:10){\n",
    "  a = greedy(alpha[al,])\n",
    "  print(\"cluster\")\n",
    "  print(a)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-domestic",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Minimal Working Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-subject",
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-recycling",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-distributor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
